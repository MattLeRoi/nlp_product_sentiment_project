{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mleroi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mleroi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import nltk\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('judge-1377884607_tweet_product_company.csv', encoding='latin1')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9065 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9065 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['tweet_text'], inplace=True)\n",
    "df.drop_duplicates(subset=['tweet_text'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_df = df[(df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Positive emotion') | (df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Negative emotion')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_tweets = pos_neg_df['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_sentiment = pos_neg_df['is_there_an_emotion_directed_at_a_brand_or_product'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8391292055414192"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_count = pos_neg_sentiment.value_counts()\n",
    "sentiment_count[0]/sum(sentiment_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pos_neg_tweets,pos_neg_sentiment, test_size=0.15, random_state=42, stratify=pos_neg_sentiment)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline(pipeline, X, y, name=\"Test\"):\n",
    "    \"\"\"Evaluate an sklearn pipeline with a KerasClassifier at the end.\"\"\"\n",
    "    \n",
    "    print(f\"--- {name} Evaluation ---\")\n",
    "    \n",
    "    # sklearn accuracy via pipeline.score\n",
    "    acc = pipeline.score(X, y)\n",
    "    print(f\"{name} Accuracy (pipeline.score): {acc:.4f}\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = pipeline.predict(X)\n",
    "    \n",
    "    # sklearn metrics\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    \n",
    "    # Keras evaluation (loss + acc)\n",
    "    model = pipeline.named_steps[\"clf\"].model\n",
    "    Xt = pipeline.named_steps[\"tok\"].transform(\n",
    "        pipeline.named_steps[\"prep\"].transform(X)\n",
    "    )\n",
    "    loss, keras_acc = model.evaluate(Xt, y, verbose=0)\n",
    "    print(f\"\\nKeras evaluate -> Loss: {loss:.4f}, Accuracy: {keras_acc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"sklearn_acc\": acc,\n",
    "        \"keras_loss\": loss,\n",
    "        \"keras_acc\": keras_acc,\n",
    "        \"y_pred\": y_pred\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipe(X,y,num_words=2000, remove_stopwords=False, lemmatize=False, num_epochs=100, show_results=False):\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 1: Custom text prep transformer\n",
    "    # ---------------------------\n",
    "\n",
    "    class TextPrep(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self):\n",
    "            self.remove_stopwords = remove_stopwords\n",
    "            self.lemmatize = lemmatize\n",
    "            self.stop_words = set(stopwords.words(\"english\"))\n",
    "            self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        def get_wordnet_pos(self, treebank_tag):\n",
    "            \"\"\"Map POS tag to WordNet format for better lemmatization\"\"\"\n",
    "            if treebank_tag.startswith(\"J\"):\n",
    "                return wordnet.ADJ\n",
    "            elif treebank_tag.startswith(\"V\"):\n",
    "                return wordnet.VERB\n",
    "            elif treebank_tag.startswith(\"N\"):\n",
    "                return wordnet.NOUN\n",
    "            elif treebank_tag.startswith(\"R\"):\n",
    "                return wordnet.ADV\n",
    "            else:\n",
    "                return wordnet.NOUN  # fallback\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X = X.ravel()\n",
    "            X = [str(x) for x in X]\n",
    "\n",
    "            processed = []\n",
    "            for text in X:\n",
    "                words = word_tokenize(text)\n",
    "\n",
    "                # Remove stopwords if enabled\n",
    "                if self.remove_stopwords:\n",
    "                    words = [w for w in words if w.lower() not in self.stop_words]\n",
    "\n",
    "                # Lemmatization if enabled\n",
    "                if self.lemmatize:\n",
    "                    pos_tags = pos_tag(words)\n",
    "                    words = [self.lemmatizer.lemmatize(w, self.get_wordnet_pos(tag)) \n",
    "                             for w, tag in pos_tags]\n",
    "                processed.append(\" \".join(words))\n",
    "\n",
    "            return processed        \n",
    "        \n",
    "    # ---------------------------\n",
    "    # Step 2: Wrap tokenizer\n",
    "    # ---------------------------\n",
    "    class KerasTokenizer(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, mode=\"binary\"):\n",
    "            self.num_words = num_words\n",
    "            self.mode = mode\n",
    "            self.tokenizer = Tokenizer(num_words=self.num_words)\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            self.tokenizer.fit_on_texts(X)\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            return self.tokenizer.texts_to_matrix(X, mode=self.mode)    \n",
    "      \n",
    "    # ---------------------------\n",
    "    # Step 3: Build model factory\n",
    "    # ---------------------------\n",
    "    def build_model(input_dim, n_classes):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(50, activation=\"relu\", input_shape=(input_dim,)))\n",
    "        model.add(Dense(25, activation=\"relu\"))\n",
    "        model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "        model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 4: Setup pipeline\n",
    "    # ---------------------------\n",
    "    n_classes = len(np.unique(y_train))  # adjust to your labels\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"prep\", TextPrep()),\n",
    "        (\"tok\", KerasTokenizer()),\n",
    "        (\"clf\", KerasClassifier(\n",
    "            build_fn=lambda: build_model(\n",
    "                input_dim=pipeline.named_steps[\"tok\"].num_words, \n",
    "                n_classes=n_classes\n",
    "            ),\n",
    "            epochs=num_epochs,\n",
    "            batch_size=256,\n",
    "            verbose=0,\n",
    "            validation_split=0.2\n",
    "            , callbacks=[EarlyStopping(monitor=\"val_accuracy\", patience=15, restore_best_weights=True)]\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Step 5: Fit\n",
    "    # ---------------------------\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # ---------------------------\n",
    "    # Step 6: Test results\n",
    "    # ---------------------------   \n",
    "    \n",
    "    # Access history directly (no `.history`)\n",
    "    pipe_history = pipeline.named_steps[\"clf\"].history_\n",
    "\n",
    "    \"\"\"test_acc = pipeline.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Detailed classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\"\"\"\n",
    "    \n",
    "    if show_results:\n",
    "        # Plot accuracy\n",
    "        print(\"Max Val Accuracy:\", max(pipe_history[\"val_accuracy\"]))\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(pipe_history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "        if \"val_accuracy\" in pipe_history:\n",
    "            plt.plot(pipe_history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "        plt.title(\"Epoch vs Accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return max(pipe_history[\"val_accuracy\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number_of_words  val accuracy remove_stopwords lemmatize\n",
      "0              100        0.8522            False     False\n",
      "1              100        0.8488            False      True\n",
      "2              100        0.8405             True     False\n",
      "3              100        0.8372             True      True\n",
      "4              500        0.8754            False     False\n",
      "5              500        0.8787            False      True\n",
      "6              500        0.8771             True     False\n",
      "7              500        0.8804             True      True\n",
      "8             1000        0.8771            False     False\n",
      "9             1000        0.8837            False      True\n",
      "10            1000        0.8704             True     False\n",
      "11            1000        0.8787             True      True\n",
      "12            2000        0.8787            False     False\n",
      "13            2000        0.8837            False      True\n",
      "14            2000        0.8787             True     False\n",
      "15            2000        0.8937             True      True\n",
      "16            5000        0.8804            False     False\n",
      "17            5000        0.8821            False      True\n",
      "18            5000        0.8821             True     False\n",
      "19            5000        0.8854             True      True\n"
     ]
    }
   ],
   "source": [
    "num_words_list = [100, 500, 1000, 2000, 5000]\n",
    "results=pd.DataFrame(columns=[\"number_of_words\",\"val accuracy\", 'remove_stopwords', 'lemmatize'])\n",
    "for x in num_words_list:\n",
    "    for stop_tf in [False,True]:\n",
    "        for lem_tf in [False,True]:\n",
    "            acc=round(run_pipe(X_train,y_train, num_words=x,remove_stopwords=stop_tf, lemmatize=lem_tf),4)\n",
    "            new_row_data = {'number_of_words': [x], 'val accuracy': [acc], 'remove_stopwords': [stop_tf], 'lemmatize': [lem_tf]}\n",
    "            new_row = pd.DataFrame(new_row_data)\n",
    "            results = pd.concat([results,new_row], ignore_index=True)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipe(X_train,y_train, num_words=500, num_epochs=300, remove_stopwords=False, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_pipe(X_train,y_train, num_words=500, num_epochs=300, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipe(X_train,y_train, num_words=1000, num_epochs=300, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipe(X_train,y_train, num_words=2000, num_epochs=300, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipe(X_train,y_train, num_words=5000, num_epochs=300, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipe(X_train,y_train, num_words=2000, num_epochs=300, remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipe(X_train,y_train, num_words=2000, num_epochs=300, remove_stopwords=False, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipe(X_train,y_train, num_words=2000, num_epochs=300, remove_stopwords=True, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
