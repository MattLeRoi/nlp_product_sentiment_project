{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tool to analyze sentiment for products based on Twitter posts, to be used by companies to monitor public perception of their products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import nltk\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('judge-1377884607_tweet_product_company.csv', encoding='latin1')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['tweet_text'], inplace=True)\n",
    "df.drop_duplicates(subset=['tweet_text'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_df = df[(df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Positive emotion') | (df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Negative emotion')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_tweets = pos_neg_df['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_sentiment = pos_neg_df['is_there_an_emotion_directed_at_a_brand_or_product'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count = pos_neg_sentiment.value_counts()\n",
    "print(f'Sentiment count: \\n{sentiment_count}')\n",
    "print(f'Positive: {round(sentiment_count[0]/sum(sentiment_count)*100,1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pos_neg_tweets,pos_neg_sentiment, \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=pos_neg_sentiment)\n",
    "# X_val = X_train[-int(len(X_train) * 0.2):]\n",
    "# y_val = y_train[-int(len(y_train) * 0.2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_macro(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Multiclass F1 Score (macro average) for Keras.\n",
    "    Works with sparse categorical crossentropy labels.\n",
    "    \"\"\"\n",
    "    # Convert y_true to one-hot\n",
    "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1])\n",
    "    \n",
    "    # Binarize predictions\n",
    "    y_pred = tf.one_hot(tf.argmax(y_pred, axis=-1), depth=tf.shape(y_pred)[-1])\n",
    "    \n",
    "    # True positives, false positives, false negatives\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, \"float\"), axis=0)\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, \"float\"), axis=0)\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), \"float\"), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "  \n",
    "    # Macro average (mean across classes)\n",
    "    return tf.reduce_mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipe(X,y, num_words=2000, \n",
    "             remove_stopwords=False, \n",
    "             lemmatize=False, \n",
    "             num_epochs=200, \n",
    "             show_results=False, \n",
    "             balance_classes=False):\n",
    "\n",
    "    # Compute weights to balance positive and negative comments to combat data imbalance\n",
    "    classes = np.unique(y)\n",
    "    class_weights = [1]*len(classes)\n",
    "    if balance_classes:\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight=\"balanced\",\n",
    "            classes=classes,\n",
    "            y=y)\n",
    "        if len(classes) == 3:\n",
    "            class_weights=[1/.15,1/.6,1/.4]\n",
    "\n",
    "    class_weights = dict(zip(classes,class_weights))\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 1: Custom text prep transformer\n",
    "    # ---------------------------\n",
    "\n",
    "    class TextPrep(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self):\n",
    "            self.remove_stopwords = remove_stopwords\n",
    "            self.lemmatize = lemmatize\n",
    "            self.stop_words = set(stopwords.words(\"english\"))\n",
    "            self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        def get_wordnet_pos(self, treebank_tag):\n",
    "            \"\"\"Map POS tag to WordNet format for better lemmatization\"\"\"\n",
    "            if treebank_tag.startswith(\"J\"):\n",
    "                return wordnet.ADJ\n",
    "            elif treebank_tag.startswith(\"V\"):\n",
    "                return wordnet.VERB\n",
    "            elif treebank_tag.startswith(\"N\"):\n",
    "                return wordnet.NOUN\n",
    "            elif treebank_tag.startswith(\"R\"):\n",
    "                return wordnet.ADV\n",
    "            else:\n",
    "                return wordnet.NOUN  # fallback\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X = X.ravel()\n",
    "            X = [str(x) for x in X]\n",
    "\n",
    "            processed = []\n",
    "            for text in X:\n",
    "                words = word_tokenize(text)\n",
    "\n",
    "                # Remove stopwords if enabled\n",
    "                if self.remove_stopwords:\n",
    "                    words = [w for w in words if w.lower() not in self.stop_words]\n",
    "\n",
    "                # Lemmatization if enabled\n",
    "                if self.lemmatize:\n",
    "                    pos_tags = pos_tag(words)\n",
    "                    words = [self.lemmatizer.lemmatize(w, self.get_wordnet_pos(tag)) \n",
    "                             for w, tag in pos_tags]\n",
    "                processed.append(\" \".join(words))\n",
    "\n",
    "            return processed        \n",
    "        \n",
    "    # ---------------------------\n",
    "    # Step 2: Wrap tokenizer\n",
    "    # ---------------------------\n",
    "    class KerasTokenizer(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, mode=\"binary\"):\n",
    "            self.num_words = num_words\n",
    "            self.mode = mode\n",
    "            self.tokenizer = Tokenizer(num_words=self.num_words)\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            self.tokenizer.fit_on_texts(X)\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            return self.tokenizer.texts_to_matrix(X, mode=self.mode)    \n",
    "      \n",
    "    # ---------------------------\n",
    "    # Step 3: Build model factory\n",
    "    # ---------------------------\n",
    "    def build_model(input_dim, n_classes):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(50, activation=\"relu\", input_shape=(input_dim,)))\n",
    "        model.add(Dense(25, activation=\"relu\"))\n",
    "        model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "        model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=['accuracy'],\n",
    "            weighted_metrics=[]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 4: Setup pipeline\n",
    "    # ---------------------------\n",
    "    n_classes = len(np.unique(y))  # adjust to your labels\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"prep\", TextPrep()),\n",
    "        (\"tok\", KerasTokenizer()),\n",
    "        (\"clf\", KerasClassifier(\n",
    "            build_fn=lambda: build_model(\n",
    "                input_dim=pipeline.named_steps[\"tok\"].num_words, \n",
    "                n_classes=n_classes\n",
    "            ),\n",
    "            epochs=num_epochs,\n",
    "            batch_size=256,\n",
    "            verbose=0,\n",
    "            validation_split=0.2, \n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)],\n",
    "            class_weight=class_weights\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Step 5: Fit\n",
    "    # ---------------------------\n",
    "    pipeline.fit(X, y)\n",
    "        \n",
    "    # ---------------------------\n",
    "    # Step 6: Test results\n",
    "    # ---------------------------   \n",
    "    \n",
    "    # Access history directly (no `.history`)\n",
    "    pipe_history = pipeline.named_steps[\"clf\"].history_\n",
    "\n",
    "#     test_acc = pipeline.score(X_test, y_test)\n",
    "#     print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "    X_val = X[-int(len(X) * 0.2):]\n",
    "    y_val = y[-int(len(y) * 0.2):]\n",
    "\n",
    "    # Get predictions and F1 score\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    pipe_f1 = f1_score(y_val, y_pred, average='macro')\n",
    "#     print(y_val.value_counts())\n",
    "    print('\\nPredictions:')\n",
    "    display(pd.DataFrame(y_pred).value_counts())\n",
    "\n",
    "    # Detailed classification report\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if show_results:\n",
    "        # Confusion matrix\n",
    "        print(confusion_matrix(y_val, y_pred))\n",
    "        # Plot accuracy\n",
    "        print(\"Max Val Accuracy:\", max(pipe_history[\"val_accuracy\"]), accuracy_score(y_val, y_pred))\n",
    "        print(\"F1 score: \", pipe_f1)\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(pipe_history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "        if \"val_accuracy\" in pipe_history:\n",
    "            plt.plot(pipe_history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "        plt.title(\"Epoch vs Accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return max(pipe_history[\"val_accuracy\"]), pipe_f1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_check (X_par, y_par, num_words_list, plot=True, balance_classes=False, show_results=False):\n",
    "    \n",
    "    results=pd.DataFrame(columns=[\"number_of_words\",\"val_accuracy\", 'remove_stopwords', 'lemmatize', 'f1'])\n",
    "    i=1\n",
    "    for x in num_words_list:\n",
    "        for stop_tf in [False,True]:\n",
    "            for lem_tf in [False,True]:\n",
    "                acc, f1=run_pipe(X_par,y_par, \n",
    "                                 num_words=x,\n",
    "                                 remove_stopwords=stop_tf, \n",
    "                                 lemmatize=lem_tf, \n",
    "                                 balance_classes=balance_classes, \n",
    "                                 show_results=show_results)\n",
    "                \n",
    "                print(f'({i} of {len(num_words_list)*4}) Stopwords: {stop_tf}, Lemmatize: {lem_tf}, Number of words: {x}, Val accuracy: {round(acc,4)}, F1 score: {round(f1,4)}')\n",
    "                new_row_data = {'number_of_words': [x], 'val_accuracy': [acc], 'remove_stopwords': [stop_tf], 'lemmatize': [lem_tf], 'f1': [f1]}\n",
    "                new_row = pd.DataFrame(new_row_data)\n",
    "                results = pd.concat([results,new_row], ignore_index=True)\n",
    "                i += 1\n",
    "    results[\"config\"] = results.apply(\n",
    "        lambda row: f\"Stopwords={row['remove_stopwords']}, Lemmatize={row['lemmatize']}\", axis=1\n",
    "    )\n",
    "\n",
    "    results = results.sort_values(\"number_of_words\")\n",
    "\n",
    "    if plot:\n",
    "        fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "        sns.lineplot(\n",
    "            data=results,\n",
    "            x=\"number_of_words\",\n",
    "            y=\"val_accuracy\",\n",
    "            hue=\"config\",\n",
    "            style=\"config\",\n",
    "            ax=ax1,\n",
    "            markers=True,\n",
    "            dashes=False)\n",
    "        \n",
    "        plt.title(\"Validation Accuracy vs Number of Words\", fontsize=14)\n",
    "        plt.xlabel(\"Number of Words\", fontsize=12)\n",
    "        plt.ylabel(\"Validation Accuracy\", fontsize=12)\n",
    "        plt.legend(title=\"Preprocessing Config\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "        fig, ax2 = plt.subplots(figsize=(10,6))\n",
    "        \n",
    "        sns.lineplot(\n",
    "            data=results,\n",
    "            x=\"number_of_words\",\n",
    "            y=\"f1\",\n",
    "            hue=\"config\",\n",
    "            style=\"config\",\n",
    "            ax=ax2,\n",
    "            markers=True,\n",
    "            dashes=True)\n",
    "        plt.title(\"Validation F1 Score vs Number of Words\", fontsize=14)\n",
    "        plt.xlabel(\"Number of Words\", fontsize=12)\n",
    "        plt.ylabel(\"Validation F1 Score\", fontsize=12)\n",
    "        plt.legend(title=\"Preprocessing Config\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count = y_test.value_counts()\n",
    "print(f'Sentiment count: \\n{sentiment_count}')\n",
    "sentiment_count[0]/sum(sentiment_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_words_list = [300, 1000, 2000, 5000]\n",
    "results = parameter_check(X_train,y_train, num_words_list, show_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add another preprocessing step? There was somethng i was thinking about that i can't remember now\n",
    "Add step to artificially increase negative comments. can't remember the name for it. Unbalanced data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_words_list = [300, 1000, 2000, 5000]\n",
    "results = parameter_check(X_train,y_train, num_words_list, balance_classes=True, show_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_pipe(X_train,y_train, num_words=500, num_epochs=300, remove_stopwords=False, lemmatize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# don't use X_test, y_test in final version. print val results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add neutral/can't tell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_df = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] != \"I can't tell\"].sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets = rand_df['tweet_text']\n",
    "sentiment = rand_df['is_there_an_emotion_directed_at_a_brand_or_product'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(tweets,sentiment, test_size=0.15, random_state=7, stratify=sentiment)\n",
    "# X_val_all = X_train_all[-int(len(X_train_all) * 0.2):]\n",
    "# y_val_all = y_train_all[-int(len(y_train_all) * 0.2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "round(sentiment.value_counts()/len(sentiment)*100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(y_train_all.value_counts()/len(y_train_all)*100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(y_test_all.value_counts()/len(y_test_all)*100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_all = y_train_all[-int(len(y_train_all) * 0.2):]\n",
    "round(y_val_all.value_counts()/len(y_val_all)*100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_words_list = [300, 1000, 2000, 5000]\n",
    "results = parameter_check(X_train_all,y_train_all, num_words_list, balance_classes=False, show_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "762/(31+71+595+55+762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_words_list = [300, 1000, 2000, 5000]\n",
    "results = parameter_check(X_train_all,y_train_all, num_words_list, balance_classes=True, show_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_all.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
