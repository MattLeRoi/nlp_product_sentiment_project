{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4 project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 4: Natural Language Processing (NLP)\n",
    "If you choose this option, you'll build an NLP model to analyze Twitter sentiment about Apple and Google products. The dataset comes from CrowdFlower via data.world. Human raters rated the sentiment in over 9,000 Tweets as positive, negative, or neither.\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "Build a model that can rate the sentiment of a Tweet based on its content.\n",
    "\n",
    "Aim for a Proof of Concept\n",
    "There are many approaches to NLP problems - start with something simple and iterate from there. For example, you could start by limiting your analysis to positive and negative Tweets only, allowing you to build a binary classifier. Then you could add in the neutral Tweets to build out a multiclass classifier. You may also consider using some of the more advanced NLP methods in the Mod 4 Appendix.\n",
    "\n",
    "Evaluation\n",
    "Evaluating multiclass classifiers can be trickier than binary classifiers because there are multiple ways to mis-classify an observation, and some errors are more problematic than others. Use the business problem that your NLP project sets out to solve to inform your choice of evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "The notebook should include a summary at the beginning that briefly and accurately describes your process. The summary should be approximately 250 words -- about the size of a research paper abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "\n",
    "|  ||\n",
    "|:-----|:----:|\n",
    "|lines total     |9093     |\n",
    "|have \"directed_at\" product  |3291     |\n",
    "\n",
    "\n",
    "|Sentiment  |Count|\n",
    "|:-----|:----:|\n",
    "|No emotion toward brand or product     |5389     |\n",
    "|Positive emotion     |2978     |\n",
    "|Negative emotion     |570     |\n",
    "|I can't tell     |156     |\n",
    "\n",
    "\n",
    "iPad                               946<br>\n",
    "Apple                              661<br>\n",
    "iPad or iPhone App                 470<br>\n",
    "Google                             430<br>\n",
    "iPhone                             297<br>\n",
    "Other Google product or service    293<br>\n",
    "Android App                         81<br>\n",
    "Android                             78<br>\n",
    "Other Apple product or service      35\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: KNN + Pipelines [Suggested time: 20 minutes]\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mleroi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mleroi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, silhouette_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('judge-1377884607_tweet_product_company.csv', encoding='latin1')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df=df.dropna(subset=['tweet_text']).copy()\n",
    "processed_df.drop_duplicates(subset=['tweet_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9065 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9065 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                               943\n",
       "Apple                              659\n",
       "iPad or iPhone App                 469\n",
       "Google                             428\n",
       "iPhone                             296\n",
       "Other Google product or service    293\n",
       "Android App                         80\n",
       "Android                             77\n",
       "Other Apple product or service      35\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['emotion_in_tweet_is_directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5372\n",
       "Positive emotion                      2968\n",
       "Negative emotion                       569\n",
       "I can't tell                           156\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9077</th>\n",
       "      <td>@mention your PR guy just convinced me to swit...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9079</th>\n",
       "      <td>&amp;quot;papyrus...sort of like the ipad&amp;quot; - ...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9080</th>\n",
       "      <td>Diller says Google TV &amp;quot;might be run over ...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>I've always used Camera+ for my iPhone b/c it ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3537 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9077  @mention your PR guy just convinced me to swit...   \n",
       "9079  &quot;papyrus...sort of like the ipad&quot; - ...   \n",
       "9080  Diller says Google TV &quot;might be run over ...   \n",
       "9085  I've always used Camera+ for my iPhone b/c it ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "\n",
       "      emotion_in_tweet_is_directed_at  \\\n",
       "0                              iPhone   \n",
       "1                  iPad or iPhone App   \n",
       "2                                iPad   \n",
       "3                  iPad or iPhone App   \n",
       "4                              Google   \n",
       "...                               ...   \n",
       "9077                           iPhone   \n",
       "9079                             iPad   \n",
       "9080  Other Google product or service   \n",
       "9085               iPad or iPhone App   \n",
       "9088                             iPad   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9077                                   Positive emotion  \n",
       "9079                                   Positive emotion  \n",
       "9080                                   Negative emotion  \n",
       "9085                                   Positive emotion  \n",
       "9088                                   Positive emotion  \n",
       "\n",
       "[3537 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_df = processed_df[(processed_df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Positive emotion') | (processed_df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Negative emotion')]\n",
    "pos_neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6230 unique tokens.\n",
      "Dimensions of our coded results: (3537, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw text complaints\n",
    "pos_neg_tweets = pos_neg_df['tweet_text'] \n",
    "\n",
    "# Initialize a tokenizer \n",
    "tokenizer = Tokenizer(num_words=2000) \n",
    "\n",
    "# Fit it to the tweets\n",
    "tokenizer.fit_on_texts(pos_neg_tweets) \n",
    "\n",
    "# Similar to sequences, but returns a numpy array\n",
    "one_hot_results= tokenizer.texts_to_matrix(pos_neg_tweets, mode='binary') \n",
    "\n",
    "# Useful if we wish to decode (more explanation below)\n",
    "word_index = tokenizer.word_index \n",
    "\n",
    "# Tokens are the number of unique words across the corpus\n",
    "print('Found %s unique tokens.' % len(word_index)) \n",
    "\n",
    "# Our coded data\n",
    "print('Dimensions of our coded results:', np.shape(one_hot_results)) \n",
    "one_hot_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sxsw', 3686), ('mention', 2505), ('the', 1903), ('to', 1413), ('link', 1316), ('ipad', 1206), ('at', 1162), ('rt', 1071), ('for', 1027), ('apple', 1003), ('a', 950), ('google', 825), ('is', 802), ('of', 771), ('in', 759), ('iphone', 702), ('and', 677), ('quot', 639), ('store', 595), ('i', 582)]\n"
     ]
    }
   ],
   "source": [
    "sorted_word_list = sorted(tokenizer.word_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "print(sorted_word_list[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class labels:\n",
      "['Negative emotion', 'Positive emotion']\n",
      "\n",
      "\n",
      "New product labels:\n",
      "[0 1 1 ... 0 1 1]\n",
      "\n",
      "\n",
      "One hot labels; 2 binary columns, one for each of the categories.\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "One hot labels shape:\n",
      "(3537, 2)\n"
     ]
    }
   ],
   "source": [
    "# pos_neg_sentiment = [1 for sent in pos_neg_df['is_there_an_emotion_directed_at_a_brand_or_product']]\n",
    "# len(pos_neg_sentiment)\n",
    "\n",
    "pos_neg_sentiment = pos_neg_df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
    "\n",
    "# Initialize\n",
    "le = LabelEncoder() \n",
    "le.fit(pos_neg_sentiment)\n",
    "print('Original class labels:')\n",
    "print(list(le.classes_))\n",
    "print('\\n')\n",
    "pos_neg_sentiment_cat = le.transform(pos_neg_sentiment)  \n",
    "\n",
    "# If you wish to retrieve the original descriptive labels post production\n",
    "# list(le.inverse_transform([0, 1, 3, 3, 0, 6, 4])) \n",
    "\n",
    "print('New product labels:')\n",
    "print(pos_neg_sentiment_cat)\n",
    "print('\\n')\n",
    "\n",
    "# Each row will be all zeros except for the category for that observation \n",
    "print('One hot labels; 2 binary columns, one for each of the categories.') \n",
    "pos_neg_sentiment_onehot = to_categorical(pos_neg_sentiment_cat)\n",
    "print(pos_neg_sentiment_onehot)\n",
    "print('\\n')\n",
    "\n",
    "print('One hot labels shape:')\n",
    "print(np.shape(pos_neg_sentiment_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(one_hot_results,pos_neg_sentiment_onehot, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Two layers with relu activation\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "\n",
    "# One layer with softmax activation \n",
    "model.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6449 - accuracy: 0.8032 - val_loss: 0.6159 - val_accuracy: 0.8405\n",
      "Epoch 2/120\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5970 - accuracy: 0.8403 - val_loss: 0.5731 - val_accuracy: 0.8372\n",
      "Epoch 3/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5562 - accuracy: 0.8407 - val_loss: 0.5371 - val_accuracy: 0.8372\n",
      "Epoch 4/120\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5226 - accuracy: 0.8407 - val_loss: 0.5083 - val_accuracy: 0.8372\n",
      "Epoch 5/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4962 - accuracy: 0.8407 - val_loss: 0.4861 - val_accuracy: 0.8372\n",
      "Epoch 6/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4757 - accuracy: 0.8407 - val_loss: 0.4704 - val_accuracy: 0.8372\n",
      "Epoch 7/120\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4612 - accuracy: 0.8407 - val_loss: 0.4590 - val_accuracy: 0.8372\n",
      "Epoch 8/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4507 - accuracy: 0.8407 - val_loss: 0.4512 - val_accuracy: 0.8372\n",
      "Epoch 9/120\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4432 - accuracy: 0.8407 - val_loss: 0.4449 - val_accuracy: 0.8372\n",
      "Epoch 10/120\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4373 - accuracy: 0.8407 - val_loss: 0.4409 - val_accuracy: 0.8372\n",
      "Epoch 11/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.8407 - val_loss: 0.4381 - val_accuracy: 0.8372\n",
      "Epoch 12/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.8407 - val_loss: 0.4360 - val_accuracy: 0.8372\n",
      "Epoch 13/120\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4281 - accuracy: 0.8407 - val_loss: 0.4347 - val_accuracy: 0.8372\n",
      "Epoch 14/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.8407 - val_loss: 0.4335 - val_accuracy: 0.8372\n",
      "Epoch 15/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.8407 - val_loss: 0.4326 - val_accuracy: 0.8372\n",
      "Epoch 16/120\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4240 - accuracy: 0.8407 - val_loss: 0.4319 - val_accuracy: 0.8372\n",
      "Epoch 17/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.8407 - val_loss: 0.4313 - val_accuracy: 0.8372\n",
      "Epoch 18/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8407 - val_loss: 0.4308 - val_accuracy: 0.8372\n",
      "Epoch 19/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.8407 - val_loss: 0.4303 - val_accuracy: 0.8372\n",
      "Epoch 20/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.8407 - val_loss: 0.4299 - val_accuracy: 0.8372\n",
      "Epoch 21/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8407 - val_loss: 0.4295 - val_accuracy: 0.8372\n",
      "Epoch 22/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8407 - val_loss: 0.4290 - val_accuracy: 0.8372\n",
      "Epoch 23/120\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.8407 - val_loss: 0.4286 - val_accuracy: 0.8372\n",
      "Epoch 24/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8407 - val_loss: 0.4282 - val_accuracy: 0.8372\n",
      "Epoch 25/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8407 - val_loss: 0.4278 - val_accuracy: 0.8372\n",
      "Epoch 26/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8407 - val_loss: 0.4274 - val_accuracy: 0.8372\n",
      "Epoch 27/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8407 - val_loss: 0.4270 - val_accuracy: 0.8372\n",
      "Epoch 28/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8407 - val_loss: 0.4266 - val_accuracy: 0.8372\n",
      "Epoch 29/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8407 - val_loss: 0.4262 - val_accuracy: 0.8372\n",
      "Epoch 30/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8407 - val_loss: 0.4259 - val_accuracy: 0.8372\n",
      "Epoch 31/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8407 - val_loss: 0.4254 - val_accuracy: 0.8372\n",
      "Epoch 32/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8407 - val_loss: 0.4250 - val_accuracy: 0.8372\n",
      "Epoch 33/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8407 - val_loss: 0.4246 - val_accuracy: 0.8372\n",
      "Epoch 34/120\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.8407 - val_loss: 0.4242 - val_accuracy: 0.8372\n",
      "Epoch 35/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8407 - val_loss: 0.4238 - val_accuracy: 0.8372\n",
      "Epoch 36/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4099 - accuracy: 0.8407 - val_loss: 0.4234 - val_accuracy: 0.8372\n",
      "Epoch 37/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.8407 - val_loss: 0.4230 - val_accuracy: 0.8372\n",
      "Epoch 38/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8407 - val_loss: 0.4226 - val_accuracy: 0.8372\n",
      "Epoch 39/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8407 - val_loss: 0.4221 - val_accuracy: 0.8372\n",
      "Epoch 40/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4073 - accuracy: 0.8407 - val_loss: 0.4218 - val_accuracy: 0.8372\n",
      "Epoch 41/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8407 - val_loss: 0.4214 - val_accuracy: 0.8372\n",
      "Epoch 42/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.8407 - val_loss: 0.4210 - val_accuracy: 0.8372\n",
      "Epoch 43/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8407 - val_loss: 0.4206 - val_accuracy: 0.8372\n",
      "Epoch 44/120\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4047 - accuracy: 0.8407 - val_loss: 0.4202 - val_accuracy: 0.8372\n",
      "Epoch 45/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8407 - val_loss: 0.4198 - val_accuracy: 0.8372\n",
      "Epoch 46/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4034 - accuracy: 0.8407 - val_loss: 0.4194 - val_accuracy: 0.8372\n",
      "Epoch 47/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8407 - val_loss: 0.4190 - val_accuracy: 0.8372\n",
      "Epoch 48/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8407 - val_loss: 0.4186 - val_accuracy: 0.8372\n",
      "Epoch 49/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.8407 - val_loss: 0.4182 - val_accuracy: 0.8372\n",
      "Epoch 50/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8407 - val_loss: 0.4179 - val_accuracy: 0.8372\n",
      "Epoch 51/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8407 - val_loss: 0.4175 - val_accuracy: 0.8372\n",
      "Epoch 52/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8407 - val_loss: 0.4171 - val_accuracy: 0.8372\n",
      "Epoch 53/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8407 - val_loss: 0.4167 - val_accuracy: 0.8372\n",
      "Epoch 54/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8407 - val_loss: 0.4163 - val_accuracy: 0.8372\n",
      "Epoch 55/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8407 - val_loss: 0.4160 - val_accuracy: 0.8372\n",
      "Epoch 56/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8407 - val_loss: 0.4156 - val_accuracy: 0.8372\n",
      "Epoch 57/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8407 - val_loss: 0.4152 - val_accuracy: 0.8372\n",
      "Epoch 58/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8407 - val_loss: 0.4148 - val_accuracy: 0.8372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8407 - val_loss: 0.4145 - val_accuracy: 0.8372\n",
      "Epoch 60/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8407 - val_loss: 0.4141 - val_accuracy: 0.8372\n",
      "Epoch 61/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8407 - val_loss: 0.4137 - val_accuracy: 0.8372\n",
      "Epoch 62/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8407 - val_loss: 0.4133 - val_accuracy: 0.8372\n",
      "Epoch 63/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8407 - val_loss: 0.4130 - val_accuracy: 0.8372\n",
      "Epoch 64/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8407 - val_loss: 0.4126 - val_accuracy: 0.8372\n",
      "Epoch 65/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8407 - val_loss: 0.4122 - val_accuracy: 0.8372\n",
      "Epoch 66/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8407 - val_loss: 0.4119 - val_accuracy: 0.8372\n",
      "Epoch 67/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8407 - val_loss: 0.4115 - val_accuracy: 0.8372\n",
      "Epoch 68/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.8407 - val_loss: 0.4111 - val_accuracy: 0.8372\n",
      "Epoch 69/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3882 - accuracy: 0.8407 - val_loss: 0.4107 - val_accuracy: 0.8372\n",
      "Epoch 70/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8407 - val_loss: 0.4104 - val_accuracy: 0.8372\n",
      "Epoch 71/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3869 - accuracy: 0.8407 - val_loss: 0.4100 - val_accuracy: 0.8372\n",
      "Epoch 72/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3862 - accuracy: 0.8407 - val_loss: 0.4096 - val_accuracy: 0.8372\n",
      "Epoch 73/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8407 - val_loss: 0.4092 - val_accuracy: 0.8372\n",
      "Epoch 74/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.8407 - val_loss: 0.4089 - val_accuracy: 0.8372\n",
      "Epoch 75/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8407 - val_loss: 0.4086 - val_accuracy: 0.8372\n",
      "Epoch 76/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.8407 - val_loss: 0.4082 - val_accuracy: 0.8372\n",
      "Epoch 77/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.8407 - val_loss: 0.4078 - val_accuracy: 0.8372\n",
      "Epoch 78/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8407 - val_loss: 0.4073 - val_accuracy: 0.8372\n",
      "Epoch 79/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8407 - val_loss: 0.4069 - val_accuracy: 0.8372\n",
      "Epoch 80/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8407 - val_loss: 0.4066 - val_accuracy: 0.8372\n",
      "Epoch 81/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.8407 - val_loss: 0.4062 - val_accuracy: 0.8372\n",
      "Epoch 82/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8407 - val_loss: 0.4059 - val_accuracy: 0.8372\n",
      "Epoch 83/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3788 - accuracy: 0.8407 - val_loss: 0.4055 - val_accuracy: 0.8372\n",
      "Epoch 84/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8407 - val_loss: 0.4050 - val_accuracy: 0.8372\n",
      "Epoch 85/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8407 - val_loss: 0.4047 - val_accuracy: 0.8372\n",
      "Epoch 86/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3766 - accuracy: 0.8407 - val_loss: 0.4042 - val_accuracy: 0.8372\n",
      "Epoch 87/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.8407 - val_loss: 0.4039 - val_accuracy: 0.8372\n",
      "Epoch 88/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8407 - val_loss: 0.4035 - val_accuracy: 0.8372\n",
      "Epoch 89/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8407 - val_loss: 0.4031 - val_accuracy: 0.8372\n",
      "Epoch 90/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8407 - val_loss: 0.4027 - val_accuracy: 0.8372\n",
      "Epoch 91/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8407 - val_loss: 0.4023 - val_accuracy: 0.8372\n",
      "Epoch 92/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8407 - val_loss: 0.4019 - val_accuracy: 0.8372\n",
      "Epoch 93/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8407 - val_loss: 0.4016 - val_accuracy: 0.8372\n",
      "Epoch 94/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3709 - accuracy: 0.8407 - val_loss: 0.4013 - val_accuracy: 0.8372\n",
      "Epoch 95/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3701 - accuracy: 0.8407 - val_loss: 0.4008 - val_accuracy: 0.8372\n",
      "Epoch 96/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3694 - accuracy: 0.8407 - val_loss: 0.4005 - val_accuracy: 0.8372\n",
      "Epoch 97/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3687 - accuracy: 0.8407 - val_loss: 0.4002 - val_accuracy: 0.8372\n",
      "Epoch 98/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3680 - accuracy: 0.8407 - val_loss: 0.3998 - val_accuracy: 0.8372\n",
      "Epoch 99/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3673 - accuracy: 0.8407 - val_loss: 0.3994 - val_accuracy: 0.8372\n",
      "Epoch 100/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8407 - val_loss: 0.3990 - val_accuracy: 0.8372\n",
      "Epoch 101/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3658 - accuracy: 0.8407 - val_loss: 0.3985 - val_accuracy: 0.8372\n",
      "Epoch 102/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3651 - accuracy: 0.8407 - val_loss: 0.3982 - val_accuracy: 0.8372\n",
      "Epoch 103/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3643 - accuracy: 0.8407 - val_loss: 0.3978 - val_accuracy: 0.8372\n",
      "Epoch 104/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3636 - accuracy: 0.8407 - val_loss: 0.3973 - val_accuracy: 0.8372\n",
      "Epoch 105/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3629 - accuracy: 0.8407 - val_loss: 0.3971 - val_accuracy: 0.8372\n",
      "Epoch 106/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3621 - accuracy: 0.8407 - val_loss: 0.3966 - val_accuracy: 0.8372\n",
      "Epoch 107/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3613 - accuracy: 0.8407 - val_loss: 0.3963 - val_accuracy: 0.8372\n",
      "Epoch 108/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3606 - accuracy: 0.8407 - val_loss: 0.3958 - val_accuracy: 0.8372\n",
      "Epoch 109/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3598 - accuracy: 0.8407 - val_loss: 0.3954 - val_accuracy: 0.8372\n",
      "Epoch 110/120\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3591 - accuracy: 0.8407 - val_loss: 0.3950 - val_accuracy: 0.8372\n",
      "Epoch 111/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3583 - accuracy: 0.8407 - val_loss: 0.3946 - val_accuracy: 0.8372\n",
      "Epoch 112/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3576 - accuracy: 0.8407 - val_loss: 0.3942 - val_accuracy: 0.8372\n",
      "Epoch 113/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3568 - accuracy: 0.8407 - val_loss: 0.3939 - val_accuracy: 0.8372\n",
      "Epoch 114/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3560 - accuracy: 0.8407 - val_loss: 0.3935 - val_accuracy: 0.8372\n",
      "Epoch 115/120\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3553 - accuracy: 0.8407 - val_loss: 0.3930 - val_accuracy: 0.8372\n",
      "Epoch 116/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3545 - accuracy: 0.8407 - val_loss: 0.3927 - val_accuracy: 0.8372\n",
      "Epoch 117/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3537 - accuracy: 0.8407 - val_loss: 0.3922 - val_accuracy: 0.8372\n",
      "Epoch 118/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3528 - accuracy: 0.8407 - val_loss: 0.3919 - val_accuracy: 0.8372\n",
      "Epoch 119/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.8407 - val_loss: 0.3915 - val_accuracy: 0.8372\n",
      "Epoch 120/120\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3513 - accuracy: 0.8407 - val_loss: 0.3912 - val_accuracy: 0.8372\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss vs the number of epoch\n",
    "plt.plot(history.history['loss']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training accuracy vs the number of epochs\n",
    "plt.plot(history.history['accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3505896329879761, 0.8406822085380554]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the loss and accuracy for the training set \n",
    "results_train = model.evaluate(X_train, y_train)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39117908477783203, 0.8372092843055725]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the loss and accuracy for the test set \n",
    "results_val = model.evaluate(X_val, y_val)\n",
    "results_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "things to add:\n",
    "\n",
    "stopwords\n",
    "lemmetize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tune: \n",
    "\n",
    "layers, num_words, epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGEX code for 3+ characters:    r\"(?u)\\w{3,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
