{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4 project with pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 4: Natural Language Processing (NLP)\n",
    "If you choose this option, you'll build an NLP model to analyze Twitter sentiment about Apple and Google products. The dataset comes from CrowdFlower via data.world. Human raters rated the sentiment in over 9,000 Tweets as positive, negative, or neither.\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "Build a model that can rate the sentiment of a Tweet based on its content.\n",
    "\n",
    "Aim for a Proof of Concept\n",
    "There are many approaches to NLP problems - start with something simple and iterate from there. For example, you could start by limiting your analysis to positive and negative Tweets only, allowing you to build a binary classifier. Then you could add in the neutral Tweets to build out a multiclass classifier. You may also consider using some of the more advanced NLP methods in the Mod 4 Appendix.\n",
    "\n",
    "Evaluation\n",
    "Evaluating multiclass classifiers can be trickier than binary classifiers because there are multiple ways to mis-classify an observation, and some errors are more problematic than others. Use the business problem that your NLP project sets out to solve to inform your choice of evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "The notebook should include a summary at the beginning that briefly and accurately describes your process. The summary should be approximately 250 words -- about the size of a research paper abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "\n",
    "|  ||\n",
    "|:-----|:----:|\n",
    "|lines total     |9093     |\n",
    "|have \"directed_at\" product  |3291     |\n",
    "\n",
    "\n",
    "|Sentiment  |Count|\n",
    "|:-----|:----:|\n",
    "|No emotion toward brand or product     |5389     |\n",
    "|Positive emotion     |2978     |\n",
    "|Negative emotion     |570     |\n",
    "|I can't tell     |156     |\n",
    "\n",
    "\n",
    "iPad                               946<br>\n",
    "Apple                              661<br>\n",
    "iPad or iPhone App                 470<br>\n",
    "Google                             430<br>\n",
    "iPhone                             297<br>\n",
    "Other Google product or service    293<br>\n",
    "Android App                         81<br>\n",
    "Android                             78<br>\n",
    "Other Apple product or service      35\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mleroi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mleroi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder#, StandardScaler\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score #, confusion_matrix, ConfusionMatrixDisplay, silhouette_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import nltk\n",
    "# import re\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "# from nltk.stem import SnowballStemmer\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('judge-1377884607_tweet_product_company.csv', encoding='latin1')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df=df.dropna(subset=['tweet_text']).copy()\n",
    "processed_df.drop_duplicates(subset=['tweet_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9065 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9065 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                               943\n",
       "Apple                              659\n",
       "iPad or iPhone App                 469\n",
       "Google                             428\n",
       "iPhone                             296\n",
       "Other Google product or service    293\n",
       "Android App                         80\n",
       "Android                             77\n",
       "Other Apple product or service      35\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['emotion_in_tweet_is_directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5372\n",
       "Positive emotion                      2968\n",
       "Negative emotion                       569\n",
       "I can't tell                           156\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9077</th>\n",
       "      <td>@mention your PR guy just convinced me to swit...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9079</th>\n",
       "      <td>&amp;quot;papyrus...sort of like the ipad&amp;quot; - ...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9080</th>\n",
       "      <td>Diller says Google TV &amp;quot;might be run over ...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>I've always used Camera+ for my iPhone b/c it ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3537 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9077  @mention your PR guy just convinced me to swit...   \n",
       "9079  &quot;papyrus...sort of like the ipad&quot; - ...   \n",
       "9080  Diller says Google TV &quot;might be run over ...   \n",
       "9085  I've always used Camera+ for my iPhone b/c it ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "\n",
       "      emotion_in_tweet_is_directed_at  \\\n",
       "0                              iPhone   \n",
       "1                  iPad or iPhone App   \n",
       "2                                iPad   \n",
       "3                  iPad or iPhone App   \n",
       "4                              Google   \n",
       "...                               ...   \n",
       "9077                           iPhone   \n",
       "9079                             iPad   \n",
       "9080  Other Google product or service   \n",
       "9085               iPad or iPhone App   \n",
       "9088                             iPad   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9077                                   Positive emotion  \n",
       "9079                                   Positive emotion  \n",
       "9080                                   Negative emotion  \n",
       "9085                                   Positive emotion  \n",
       "9088                                   Positive emotion  \n",
       "\n",
       "[3537 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_df = processed_df[(processed_df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Positive emotion') | (processed_df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Negative emotion')]\n",
    "pos_neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6230 unique tokens.\n",
      "Dimensions of our coded results: (3537, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw text complaints\n",
    "pos_neg_tweets = pos_neg_df['tweet_text'] \n",
    "\n",
    "# Initialize a tokenizer \n",
    "tokenizer = Tokenizer(num_words=2000) \n",
    "\n",
    "# Fit it to the tweets\n",
    "tokenizer.fit_on_texts(pos_neg_tweets) \n",
    "\n",
    "# Similar to sequences, but returns a numpy array\n",
    "one_hot_results= tokenizer.texts_to_matrix(pos_neg_tweets, mode='binary') \n",
    "\n",
    "# Useful if we wish to decode (more explanation below)\n",
    "word_index = tokenizer.word_index \n",
    "\n",
    "# Tokens are the number of unique words across the corpus\n",
    "print('Found %s unique tokens.' % len(word_index)) \n",
    "\n",
    "# Our coded data\n",
    "print('Dimensions of our coded results:', np.shape(one_hot_results)) \n",
    "one_hot_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sxsw', 3686), ('mention', 2505), ('the', 1903), ('to', 1413), ('link', 1316), ('ipad', 1206), ('at', 1162), ('rt', 1071), ('for', 1027), ('apple', 1003), ('a', 950), ('google', 825), ('is', 802), ('of', 771), ('in', 759), ('iphone', 702), ('and', 677), ('quot', 639), ('store', 595), ('i', 582)]\n"
     ]
    }
   ],
   "source": [
    "sorted_word_list = sorted(tokenizer.word_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "print(sorted_word_list[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class labels:\n",
      "['Negative emotion', 'Positive emotion']\n",
      "\n",
      "\n",
      "New product labels:\n",
      "[0 1 1 ... 0 1 1]\n",
      "\n",
      "\n",
      "One hot labels; 2 binary columns, one for each of the categories.\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "One hot labels shape:\n",
      "(3537, 2)\n"
     ]
    }
   ],
   "source": [
    "# pos_neg_sentiment = [1 for sent in pos_neg_df['is_there_an_emotion_directed_at_a_brand_or_product']]\n",
    "# len(pos_neg_sentiment)\n",
    "\n",
    "pos_neg_sentiment = pos_neg_df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
    "\n",
    "# Initialize\n",
    "le = LabelEncoder() \n",
    "le.fit(pos_neg_sentiment)\n",
    "print('Original class labels:')\n",
    "print(list(le.classes_))\n",
    "print('\\n')\n",
    "pos_neg_sentiment_cat = le.transform(pos_neg_sentiment)  \n",
    "\n",
    "# If you wish to retrieve the original descriptive labels post production\n",
    "# list(le.inverse_transform([0, 1, 3, 3, 0, 6, 4])) \n",
    "\n",
    "print('New product labels:')\n",
    "print(pos_neg_sentiment_cat)\n",
    "print('\\n')\n",
    "\n",
    "# Each row will be all zeros except for the category for that observation \n",
    "print('One hot labels; 2 binary columns, one for each of the categories.') \n",
    "pos_neg_sentiment_onehot = to_categorical(pos_neg_sentiment_cat)\n",
    "print(pos_neg_sentiment_onehot)\n",
    "print('\\n')\n",
    "\n",
    "print('One hot labels shape:')\n",
    "print(np.shape(pos_neg_sentiment_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(one_hot_results,pos_neg_sentiment_onehot, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Two layers with relu activation\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "\n",
    "# One layer with softmax activation \n",
    "model.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 1s 24ms/step - loss: 0.6414 - accuracy: 0.8286 - val_loss: 0.6199 - val_accuracy: 0.8372\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6034 - accuracy: 0.8407 - val_loss: 0.5836 - val_accuracy: 0.8372\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5677 - accuracy: 0.8407 - val_loss: 0.5508 - val_accuracy: 0.8372\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5364 - accuracy: 0.8407 - val_loss: 0.5228 - val_accuracy: 0.8372\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5100 - accuracy: 0.8407 - val_loss: 0.5004 - val_accuracy: 0.8372\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4888 - accuracy: 0.8407 - val_loss: 0.4820 - val_accuracy: 0.8372\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4719 - accuracy: 0.8407 - val_loss: 0.4691 - val_accuracy: 0.8372\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4599 - accuracy: 0.8407 - val_loss: 0.4589 - val_accuracy: 0.8372\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4505 - accuracy: 0.8407 - val_loss: 0.4516 - val_accuracy: 0.8372\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4437 - accuracy: 0.8407 - val_loss: 0.4461 - val_accuracy: 0.8372\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4385 - accuracy: 0.8407 - val_loss: 0.4425 - val_accuracy: 0.8372\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4350 - accuracy: 0.8407 - val_loss: 0.4398 - val_accuracy: 0.8372\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.8407 - val_loss: 0.4380 - val_accuracy: 0.8372\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4304 - accuracy: 0.8407 - val_loss: 0.4364 - val_accuracy: 0.8372\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.8407 - val_loss: 0.4350 - val_accuracy: 0.8372\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4270 - accuracy: 0.8407 - val_loss: 0.4341 - val_accuracy: 0.8372\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4259 - accuracy: 0.8407 - val_loss: 0.4333 - val_accuracy: 0.8372\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.8407 - val_loss: 0.4327 - val_accuracy: 0.8372\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4240 - accuracy: 0.8407 - val_loss: 0.4321 - val_accuracy: 0.8372\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4232 - accuracy: 0.8407 - val_loss: 0.4316 - val_accuracy: 0.8372\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4224 - accuracy: 0.8407 - val_loss: 0.4311 - val_accuracy: 0.8372\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4217 - accuracy: 0.8407 - val_loss: 0.4307 - val_accuracy: 0.8372\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4210 - accuracy: 0.8407 - val_loss: 0.4302 - val_accuracy: 0.8372\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4203 - accuracy: 0.8407 - val_loss: 0.4298 - val_accuracy: 0.8372\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4197 - accuracy: 0.8407 - val_loss: 0.4294 - val_accuracy: 0.8372\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.8407 - val_loss: 0.4290 - val_accuracy: 0.8372\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.8407 - val_loss: 0.4286 - val_accuracy: 0.8372\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4178 - accuracy: 0.8407 - val_loss: 0.4282 - val_accuracy: 0.8372\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4171 - accuracy: 0.8407 - val_loss: 0.4278 - val_accuracy: 0.8372\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4165 - accuracy: 0.8407 - val_loss: 0.4275 - val_accuracy: 0.8372\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4159 - accuracy: 0.8407 - val_loss: 0.4271 - val_accuracy: 0.8372\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.8407 - val_loss: 0.4267 - val_accuracy: 0.8372\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.8407 - val_loss: 0.4263 - val_accuracy: 0.8372\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4140 - accuracy: 0.8407 - val_loss: 0.4259 - val_accuracy: 0.8372\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4134 - accuracy: 0.8407 - val_loss: 0.4255 - val_accuracy: 0.8372\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4128 - accuracy: 0.8407 - val_loss: 0.4251 - val_accuracy: 0.8372\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4122 - accuracy: 0.8407 - val_loss: 0.4248 - val_accuracy: 0.8372\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4116 - accuracy: 0.8407 - val_loss: 0.4244 - val_accuracy: 0.8372\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8407 - val_loss: 0.4239 - val_accuracy: 0.8372\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8407 - val_loss: 0.4235 - val_accuracy: 0.8372\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4097 - accuracy: 0.8407 - val_loss: 0.4231 - val_accuracy: 0.8372\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4090 - accuracy: 0.8407 - val_loss: 0.4227 - val_accuracy: 0.8372\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4084 - accuracy: 0.8407 - val_loss: 0.4223 - val_accuracy: 0.8372\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4078 - accuracy: 0.8407 - val_loss: 0.4219 - val_accuracy: 0.8372\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 0.8407 - val_loss: 0.4216 - val_accuracy: 0.8372\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4065 - accuracy: 0.8407 - val_loss: 0.4211 - val_accuracy: 0.8372\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4058 - accuracy: 0.8407 - val_loss: 0.4208 - val_accuracy: 0.8372\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.8407 - val_loss: 0.4204 - val_accuracy: 0.8372\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4045 - accuracy: 0.8407 - val_loss: 0.4200 - val_accuracy: 0.8372\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4039 - accuracy: 0.8407 - val_loss: 0.4196 - val_accuracy: 0.8372\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4033 - accuracy: 0.8407 - val_loss: 0.4192 - val_accuracy: 0.8372\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4026 - accuracy: 0.8407 - val_loss: 0.4189 - val_accuracy: 0.8372\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4019 - accuracy: 0.8407 - val_loss: 0.4185 - val_accuracy: 0.8372\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.8407 - val_loss: 0.4181 - val_accuracy: 0.8372\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4007 - accuracy: 0.8407 - val_loss: 0.4177 - val_accuracy: 0.8372\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8407 - val_loss: 0.4173 - val_accuracy: 0.8372\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8407 - val_loss: 0.4170 - val_accuracy: 0.8372\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.8407 - val_loss: 0.4166 - val_accuracy: 0.8372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3981 - accuracy: 0.8407 - val_loss: 0.4162 - val_accuracy: 0.8372\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3974 - accuracy: 0.8407 - val_loss: 0.4158 - val_accuracy: 0.8372\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8407 - val_loss: 0.4154 - val_accuracy: 0.8372\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.8407 - val_loss: 0.4150 - val_accuracy: 0.8372\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3955 - accuracy: 0.8407 - val_loss: 0.4146 - val_accuracy: 0.8372\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8407 - val_loss: 0.4143 - val_accuracy: 0.8372\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8407 - val_loss: 0.4139 - val_accuracy: 0.8372\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3935 - accuracy: 0.8407 - val_loss: 0.4135 - val_accuracy: 0.8372\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3929 - accuracy: 0.8407 - val_loss: 0.4131 - val_accuracy: 0.8372\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3922 - accuracy: 0.8407 - val_loss: 0.4127 - val_accuracy: 0.8372\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3916 - accuracy: 0.8407 - val_loss: 0.4123 - val_accuracy: 0.8372\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3909 - accuracy: 0.8407 - val_loss: 0.4120 - val_accuracy: 0.8372\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3903 - accuracy: 0.8407 - val_loss: 0.4116 - val_accuracy: 0.8372\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3896 - accuracy: 0.8407 - val_loss: 0.4112 - val_accuracy: 0.8372\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.8407 - val_loss: 0.4109 - val_accuracy: 0.8372\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8407 - val_loss: 0.4105 - val_accuracy: 0.8372\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3876 - accuracy: 0.8407 - val_loss: 0.4102 - val_accuracy: 0.8372\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3870 - accuracy: 0.8407 - val_loss: 0.4098 - val_accuracy: 0.8372\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3863 - accuracy: 0.8407 - val_loss: 0.4094 - val_accuracy: 0.8372\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3856 - accuracy: 0.8407 - val_loss: 0.4090 - val_accuracy: 0.8372\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3850 - accuracy: 0.8407 - val_loss: 0.4086 - val_accuracy: 0.8372\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3843 - accuracy: 0.8407 - val_loss: 0.4083 - val_accuracy: 0.8372\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3837 - accuracy: 0.8407 - val_loss: 0.4080 - val_accuracy: 0.8372\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3831 - accuracy: 0.8407 - val_loss: 0.4076 - val_accuracy: 0.8372\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3824 - accuracy: 0.8407 - val_loss: 0.4071 - val_accuracy: 0.8372\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3818 - accuracy: 0.8407 - val_loss: 0.4067 - val_accuracy: 0.8372\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3811 - accuracy: 0.8407 - val_loss: 0.4064 - val_accuracy: 0.8372\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3804 - accuracy: 0.8407 - val_loss: 0.4060 - val_accuracy: 0.8372\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3798 - accuracy: 0.8407 - val_loss: 0.4057 - val_accuracy: 0.8372\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3791 - accuracy: 0.8407 - val_loss: 0.4053 - val_accuracy: 0.8372\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.8407 - val_loss: 0.4049 - val_accuracy: 0.8372\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3777 - accuracy: 0.8407 - val_loss: 0.4045 - val_accuracy: 0.8372\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3771 - accuracy: 0.8407 - val_loss: 0.4041 - val_accuracy: 0.8372\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3765 - accuracy: 0.8407 - val_loss: 0.4038 - val_accuracy: 0.8372\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3758 - accuracy: 0.8407 - val_loss: 0.4035 - val_accuracy: 0.8372\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3751 - accuracy: 0.8407 - val_loss: 0.4032 - val_accuracy: 0.8372\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3745 - accuracy: 0.8407 - val_loss: 0.4028 - val_accuracy: 0.8372\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3738 - accuracy: 0.8407 - val_loss: 0.4025 - val_accuracy: 0.8372\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3732 - accuracy: 0.8407 - val_loss: 0.4021 - val_accuracy: 0.8372\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3725 - accuracy: 0.8407 - val_loss: 0.4018 - val_accuracy: 0.8372\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3719 - accuracy: 0.8407 - val_loss: 0.4013 - val_accuracy: 0.8372\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3713 - accuracy: 0.8407 - val_loss: 0.4010 - val_accuracy: 0.8372\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3706 - accuracy: 0.8407 - val_loss: 0.4008 - val_accuracy: 0.8372\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3700 - accuracy: 0.8407 - val_loss: 0.4004 - val_accuracy: 0.8372\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3693 - accuracy: 0.8407 - val_loss: 0.4000 - val_accuracy: 0.8372\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3686 - accuracy: 0.8407 - val_loss: 0.3996 - val_accuracy: 0.8372\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3680 - accuracy: 0.8407 - val_loss: 0.3994 - val_accuracy: 0.8372\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3674 - accuracy: 0.8407 - val_loss: 0.3990 - val_accuracy: 0.8372\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3668 - accuracy: 0.8407 - val_loss: 0.3987 - val_accuracy: 0.8372\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3661 - accuracy: 0.8407 - val_loss: 0.3982 - val_accuracy: 0.8372\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3654 - accuracy: 0.8407 - val_loss: 0.3979 - val_accuracy: 0.8372\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3648 - accuracy: 0.8407 - val_loss: 0.3974 - val_accuracy: 0.8372\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3641 - accuracy: 0.8407 - val_loss: 0.3971 - val_accuracy: 0.8372\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3635 - accuracy: 0.8407 - val_loss: 0.3968 - val_accuracy: 0.8372\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3628 - accuracy: 0.8407 - val_loss: 0.3963 - val_accuracy: 0.8372\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3622 - accuracy: 0.8407 - val_loss: 0.3960 - val_accuracy: 0.8372\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3615 - accuracy: 0.8407 - val_loss: 0.3957 - val_accuracy: 0.8372\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3609 - accuracy: 0.8407 - val_loss: 0.3953 - val_accuracy: 0.8372\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3603 - accuracy: 0.8407 - val_loss: 0.3950 - val_accuracy: 0.8372\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3596 - accuracy: 0.8407 - val_loss: 0.3947 - val_accuracy: 0.8372\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3590 - accuracy: 0.8407 - val_loss: 0.3942 - val_accuracy: 0.8372\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3584 - accuracy: 0.8407 - val_loss: 0.3940 - val_accuracy: 0.8372\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3577 - accuracy: 0.8407 - val_loss: 0.3937 - val_accuracy: 0.8372\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3571 - accuracy: 0.8407 - val_loss: 0.3934 - val_accuracy: 0.8372\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3565 - accuracy: 0.8407 - val_loss: 0.3930 - val_accuracy: 0.8372\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3558 - accuracy: 0.8407 - val_loss: 0.3926 - val_accuracy: 0.8372\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3552 - accuracy: 0.8407 - val_loss: 0.3922 - val_accuracy: 0.8372\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3546 - accuracy: 0.8407 - val_loss: 0.3919 - val_accuracy: 0.8372\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3539 - accuracy: 0.8407 - val_loss: 0.3915 - val_accuracy: 0.8372\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3532 - accuracy: 0.8407 - val_loss: 0.3912 - val_accuracy: 0.8372\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3526 - accuracy: 0.8407 - val_loss: 0.3909 - val_accuracy: 0.8372\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3520 - accuracy: 0.8407 - val_loss: 0.3907 - val_accuracy: 0.8372\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3514 - accuracy: 0.8407 - val_loss: 0.3904 - val_accuracy: 0.8372\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3507 - accuracy: 0.8407 - val_loss: 0.3899 - val_accuracy: 0.8372\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3501 - accuracy: 0.8407 - val_loss: 0.3896 - val_accuracy: 0.8372\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3494 - accuracy: 0.8407 - val_loss: 0.3891 - val_accuracy: 0.8372\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3487 - accuracy: 0.8407 - val_loss: 0.3887 - val_accuracy: 0.8372\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3480 - accuracy: 0.8407 - val_loss: 0.3885 - val_accuracy: 0.8372\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3474 - accuracy: 0.8407 - val_loss: 0.3880 - val_accuracy: 0.8372\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3468 - accuracy: 0.8407 - val_loss: 0.3877 - val_accuracy: 0.8372\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3462 - accuracy: 0.8407 - val_loss: 0.3873 - val_accuracy: 0.8372\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3455 - accuracy: 0.8407 - val_loss: 0.3869 - val_accuracy: 0.8372\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3448 - accuracy: 0.8407 - val_loss: 0.3865 - val_accuracy: 0.8372\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3442 - accuracy: 0.8407 - val_loss: 0.3862 - val_accuracy: 0.8372\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3436 - accuracy: 0.8407 - val_loss: 0.3860 - val_accuracy: 0.8372\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3429 - accuracy: 0.8407 - val_loss: 0.3856 - val_accuracy: 0.8372\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3422 - accuracy: 0.8407 - val_loss: 0.3853 - val_accuracy: 0.8372\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3416 - accuracy: 0.8407 - val_loss: 0.3851 - val_accuracy: 0.8372\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3410 - accuracy: 0.8407 - val_loss: 0.3847 - val_accuracy: 0.8372\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3403 - accuracy: 0.8407 - val_loss: 0.3845 - val_accuracy: 0.8372\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3397 - accuracy: 0.8407 - val_loss: 0.3842 - val_accuracy: 0.8372\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3389 - accuracy: 0.8407 - val_loss: 0.3837 - val_accuracy: 0.8372\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3383 - accuracy: 0.8407 - val_loss: 0.3835 - val_accuracy: 0.8372\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3376 - accuracy: 0.8407 - val_loss: 0.3831 - val_accuracy: 0.8372\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3370 - accuracy: 0.8407 - val_loss: 0.3827 - val_accuracy: 0.8372\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3364 - accuracy: 0.8407 - val_loss: 0.3823 - val_accuracy: 0.8372\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3356 - accuracy: 0.8407 - val_loss: 0.3820 - val_accuracy: 0.8372\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3349 - accuracy: 0.8407 - val_loss: 0.3819 - val_accuracy: 0.8372\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.8407 - val_loss: 0.3816 - val_accuracy: 0.8372\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3337 - accuracy: 0.8407 - val_loss: 0.3813 - val_accuracy: 0.8372\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3330 - accuracy: 0.8407 - val_loss: 0.3807 - val_accuracy: 0.8372\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3323 - accuracy: 0.8407 - val_loss: 0.3805 - val_accuracy: 0.8372\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3317 - accuracy: 0.8407 - val_loss: 0.3802 - val_accuracy: 0.8372\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3310 - accuracy: 0.8407 - val_loss: 0.3799 - val_accuracy: 0.8372\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3303 - accuracy: 0.8407 - val_loss: 0.3795 - val_accuracy: 0.8372\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3297 - accuracy: 0.8407 - val_loss: 0.3792 - val_accuracy: 0.8372\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3290 - accuracy: 0.8407 - val_loss: 0.3788 - val_accuracy: 0.8372\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3283 - accuracy: 0.8407 - val_loss: 0.3784 - val_accuracy: 0.8372\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3277 - accuracy: 0.8407 - val_loss: 0.3780 - val_accuracy: 0.8372\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3269 - accuracy: 0.8407 - val_loss: 0.3777 - val_accuracy: 0.8372\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3263 - accuracy: 0.8407 - val_loss: 0.3773 - val_accuracy: 0.8372\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3257 - accuracy: 0.8407 - val_loss: 0.3769 - val_accuracy: 0.8372\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3250 - accuracy: 0.8407 - val_loss: 0.3765 - val_accuracy: 0.8372\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3243 - accuracy: 0.8407 - val_loss: 0.3761 - val_accuracy: 0.8372\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3236 - accuracy: 0.8407 - val_loss: 0.3757 - val_accuracy: 0.8372\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3229 - accuracy: 0.8407 - val_loss: 0.3755 - val_accuracy: 0.8372\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3223 - accuracy: 0.8407 - val_loss: 0.3752 - val_accuracy: 0.8372\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3216 - accuracy: 0.8407 - val_loss: 0.3750 - val_accuracy: 0.8372\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3209 - accuracy: 0.8411 - val_loss: 0.3746 - val_accuracy: 0.8372\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3202 - accuracy: 0.8419 - val_loss: 0.3744 - val_accuracy: 0.8372\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3196 - accuracy: 0.8419 - val_loss: 0.3740 - val_accuracy: 0.8389\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3189 - accuracy: 0.8419 - val_loss: 0.3735 - val_accuracy: 0.8389\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3182 - accuracy: 0.8428 - val_loss: 0.3732 - val_accuracy: 0.8389\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3175 - accuracy: 0.8432 - val_loss: 0.3728 - val_accuracy: 0.8389\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3168 - accuracy: 0.8436 - val_loss: 0.3726 - val_accuracy: 0.8389\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3161 - accuracy: 0.8436 - val_loss: 0.3721 - val_accuracy: 0.8389\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3155 - accuracy: 0.8440 - val_loss: 0.3717 - val_accuracy: 0.8389\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3148 - accuracy: 0.8444 - val_loss: 0.3715 - val_accuracy: 0.8389\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3141 - accuracy: 0.8444 - val_loss: 0.3712 - val_accuracy: 0.8389\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3134 - accuracy: 0.8444 - val_loss: 0.3708 - val_accuracy: 0.8389\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3127 - accuracy: 0.8453 - val_loss: 0.3706 - val_accuracy: 0.8389\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3120 - accuracy: 0.8453 - val_loss: 0.3701 - val_accuracy: 0.8389\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3114 - accuracy: 0.8453 - val_loss: 0.3695 - val_accuracy: 0.8389\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3107 - accuracy: 0.8453 - val_loss: 0.3693 - val_accuracy: 0.8389\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3100 - accuracy: 0.8457 - val_loss: 0.3691 - val_accuracy: 0.8389\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3093 - accuracy: 0.8465 - val_loss: 0.3689 - val_accuracy: 0.8389\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3086 - accuracy: 0.8473 - val_loss: 0.3682 - val_accuracy: 0.8389\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3080 - accuracy: 0.8482 - val_loss: 0.3682 - val_accuracy: 0.8389\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3072 - accuracy: 0.8486 - val_loss: 0.3678 - val_accuracy: 0.8389\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3065 - accuracy: 0.8490 - val_loss: 0.3675 - val_accuracy: 0.8389\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3059 - accuracy: 0.8498 - val_loss: 0.3671 - val_accuracy: 0.8405\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3052 - accuracy: 0.8511 - val_loss: 0.3670 - val_accuracy: 0.8405\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiT0lEQVR4nO3de3Bc53nf8e+DK3EjLguQEkmAuJBULEuOLhBBirGaxJZN5yK5cWpLTmKpTcJRI46TceNGmmQcj9xp7XTq2p2oTRWHU7eNI7tO7MCWEkV2okiWCIqgRV1IiSSwoERQEgns8n7D7ekf5yy4hAFiSSx2gbO/z8wOd8+es/vg7PKHF+95z3vM3RERkegqyncBIiIyvxT0IiIRp6AXEYk4Bb2ISMQp6EVEIq4k3wVM1djY6K2trfkuQ0RkUdm1a9ewuzdN99yCC/rW1lZ6e3vzXYaIyKJiZm/O9FxGXTdmttnM9plZn5k9NMM6HzezvWa2x8y+kbZ83Mx2h7fuKy9fRETmYtYWvZkVA48CdwKDwE4z63b3vWnrrAUeBja5+zEzW5b2Eufc/absli0iIpnKpEW/Huhz97i7jwCPA3dPWee3gUfd/RiAux/NbpkiInK1Mgn6lcChtMeD4bJ064B1Zva8mfWY2ea055aYWW+4/KPTvYGZbQnX6R0aGrqS+kVEZBbZOhhbAqwFfhZYBTxrZje6+3FgtbsfNrN24B/N7FV370/f2N0fAx4D6Ozs1OQ7IiJZlEmL/jDQnPZ4Vbgs3SDQ7e6j7j4A7CcIftz9cPhvHHgGuHmONYuIyBXIJOh3AmvNrM3MyoB7gKmjZ75L0JrHzBoJunLiZlZvZuVpyzcBexERkZyZNejdfQzYCjwFvA58y933mNkjZnZXuNpTQMLM9gL/BHzW3RPAe4BeM3s5XP7F9NE62XTq/Cj/9en97D50fD5eXkRk0cqoj97dnwSenLLsc2n3HfhMeEtf5wXgxrmXObuJCfjqDw+wtKKUm5rrcvGWIiKLQmTmuqlZUoIZnDg7ku9SREQWlMgEfVGRUVtRyvFzo/kuRURkQYlM0APUVZRy/KyCXkQkXaSCvrayTC16EZEpIhX0dRWl6qMXEZkiWkFfqT56EZGpohX06qMXEfkJkQr62soyTp4fZXxC0+WIiKREKujrK0txh5PqvhERmRSpoK+rLAVQP72ISJpoBX1FGQDHNfJGRGRSpIK+Vi16EZGfEKmgr6sIgv6ERt6IiEyKVtBXqutGRGSqSAX90iXBrMvquhERuShSQV9SXETNkhKdNCUikiZSQQ/BEMsTatGLiEyKXtBXlKmPXkQkTfSCvrKUY+q6ERGZFMGgL1PXjYhImoyC3sw2m9k+M+szs4dmWOfjZrbXzPaY2TfSlt9nZgfC233ZKnwmwQyW6roREUkpmW0FMysGHgXuBAaBnWbW7e5709ZZCzwMbHL3Y2a2LFzeAPwx0Ak4sCvc9lj2f5RA6mDsxIRTVGTz9TYiIotGJi369UCfu8fdfQR4HLh7yjq/DTyaCnB3Pxou/zDwtLsnw+eeBjZnp/Tp1VaUMuFw6sLYfL6NiMiikUnQrwQOpT0eDJelWwesM7PnzazHzDZfwbZZlTo7VtMgiIgEZu26uYLXWQv8LLAKeNbMbsx0YzPbAmwBaGlpmVMhqflujp8boYXKOb2WiEgUZNKiPww0pz1eFS5LNwh0u/uouw8A+wmCP5NtcffH3L3T3TubmpqupP6fMDknvVr0IiJAZkG/E1hrZm1mVgbcA3RPWee7BK15zKyRoCsnDjwFfMjM6s2sHvhQuGze6OIjIiKXmrXrxt3HzGwrQUAXA9vcfY+ZPQL0uns3FwN9LzAOfNbdEwBm9gWCXxYAj7h7cj5+kJTailQfvYZYiohAhn307v4k8OSUZZ9Lu+/AZ8Lb1G23AdvmVmbmasM+ep0dKyISiNyZsWUlRVSXawZLEZGUyAU9BK364+fUdSMiAhEN+rrKUo2jFxEJRTboNepGRCQQzaDXnPQiIpMiGfS1usqUiMikSAZ9MFXxKMGoTxGRwhbNoK8sZWzCOTMynu9SRETyLppBH54dq356EZGIBn2tJjYTEZkUyaCfnKpYQS8iEs2gr68Ku250dqyISDSDXi16EZGLIhn0F/vo1aIXEYlk0JeXFFNVVkzijIJeRCSSQQ/QUF1GUkEvIhLdoI9VlSvoRUSIdNCXkTitoBcRiWzQN1Sp60ZEBKIc9NVlJM5c0MRmIlLwIhv0saoyRsedUxfG8l2KiEheZRT0ZrbZzPaZWZ+ZPTTN8/eb2ZCZ7Q5vv5X23Hja8u5sFn85sapyAJLqpxeRAlcy2wpmVgw8CtwJDAI7zazb3fdOWfWb7r51mpc45+43zbnSK9RQHUyDkDgzQmtjVa7fXkRkwcikRb8e6HP3uLuPAI8Dd89vWXMXC+e70QFZESl0mQT9SuBQ2uPBcNlUHzOzV8zs22bWnLZ8iZn1mlmPmX10ujcwsy3hOr1DQ0MZF385DWHQJ05fyMrriYgsVtk6GPs9oNXd3wc8DXw97bnV7t4JfBL4ipl1TN3Y3R9z905372xqaspKQak+ek2DICKFLpOgPwykt9BXhcsmuXvC3VNN568Bt6Y9dzj8Nw48A9w8h3ozVlFWTEVpsbpuRKTgZRL0O4G1ZtZmZmXAPcAlo2fM7Nq0h3cBr4fL682sPLzfCGwCph7EnTcxzXcjIjL7qBt3HzOzrcBTQDGwzd33mNkjQK+7dwOfNrO7gDEgCdwfbv4e4H+a2QTBL5UvTjNaZ97EqsrUdSMiBW/WoAdw9yeBJ6cs+1za/YeBh6fZ7gXgxjnWeNUaqso4ekoHY0WksEX2zFiABs1gKSIS7aCPVQddN5rvRkQKWaSDvrG6jJGxCc13IyIFLdJBv3zpEgCOnjyf50pERPIn0kHfVBOcNHX0pA7IikjhinTQL6sJW/QaeSMiBSzaQb80bNGfUteNiBSuSAd9TXkJS0qLOKKuGxEpYJEOejNj+dIl6roRkYIW6aAHWFZTrlE3IlLQCiDolzCkFr2IFLDIB31TTTlH1KIXkQIW+aBfvnQJZ0bGOaOzY0WkQEU+6JelTppS942IFKjoB31qLL26b0SkQEU/6HV2rIgUuMgH/fKwRa8DsiJSqCIf9LUVpZSVFKlFLyIFK/JBb2asrKvg8LFz+S5FRCQvIh/0AKvqKxg8rqAXkcKUUdCb2WYz22dmfWb20DTP329mQ2a2O7z9Vtpz95nZgfB2XzaLz1TQoj+bj7cWEcm7ktlWMLNi4FHgTmAQ2Glm3e6+d8qq33T3rVO2bQD+GOgEHNgVbnssK9VnaFV9BcOnRzg/Os6S0uJcvrWISN5l0qJfD/S5e9zdR4DHgbszfP0PA0+7ezIM96eBzVdX6tVbWV8BwKD66UWkAGUS9CuBQ2mPB8NlU33MzF4xs2+bWfOVbGtmW8ys18x6h4aGMiw9c6vqKwE4rH56ESlA2ToY+z2g1d3fR9Bq//qVbOzuj7l7p7t3NjU1Zamki1ZNtujVTy8ihSeToD8MNKc9XhUum+TuCXdPDVT/GnBrptvmwrKaJZQUmYZYikhByiTodwJrzazNzMqAe4Du9BXM7Nq0h3cBr4f3nwI+ZGb1ZlYPfChcllPFRcaKugr10YtIQZp11I27j5nZVoKALga2ufseM3sE6HX3buDTZnYXMAYkgfvDbZNm9gWCXxYAj7h7ch5+jlmtrKtQH72IFKRZgx7A3Z8Enpyy7HNp9x8GHp5h223AtjnUmBWr6it49kD2D/SKiCx0BXFmLARDLI+eusCFsfF8lyIiklMFE/SrY5W4w6GkRt6ISGEpmKDvaKoGoO/omTxXIiKSWwUT9G2NVQDEh0/nuRIRkdwqmKCvWVLKsppy4kNq0YtIYSmYoIeg+6Z/SC16ESksBRX07U1VxIfO4O75LkVEJGcKLOirOXFulOSZkXyXIiKSMwUW9MEB2X7104tIASmooF8TDrGMq59eRApIQQX9iroKykqKdEBWRApKQQV9cZHxU9fU8OrhE/kuRUQkZwoq6AFubq7jlcETjE9o5I2IFIbCC/qWes6OjLP/yKl8lyIikhMFF/Q3NdcB8NJbx/Nah4hIrhRc0K+OVVJfWcruQ8fyXYqISE4UXNCbGTc116lFLyIFo+CCHoJ++r6h05w4N5rvUkRE5l1BBv1trQ24w454It+liIjMu4IM+ltX11NZVsxzB4bzXYqIyLwryKAvKyliY3tMFwsXkYKQUdCb2WYz22dmfWb20GXW+5iZuZl1ho9bzeycme0Ob3+WrcLn6v1rG3kzcZY3E5rgTESirWS2FcysGHgUuBMYBHaaWbe7752yXg3wu8COKS/R7+43Zafc7LljXRMAzx4Y5jdiVXmuRkRk/mTSol8P9Ll73N1HgMeBu6dZ7wvAl4DzWaxv3rQ1VrGqvoIf7D2S71JEROZVJkG/EjiU9ngwXDbJzG4Bmt39iWm2bzOzl8zsn83s/dO9gZltMbNeM+sdGspNv7mZ8dGbVvLcgSHeOXEuJ+8pIpIPcz4Ya2ZFwJeBfzfN0+8ALe5+M/AZ4BtmtnTqSu7+mLt3untnU1PTXEvK2L/qXMWEw9/8+HDO3lNEJNcyCfrDQHPa41XhspQa4AbgGTM7CGwAus2s090vuHsCwN13Af3AumwUng2rY1VsaG/gW72HdB1ZEYmsTIJ+J7DWzNrMrAy4B+hOPenuJ9y90d1b3b0V6AHucvdeM2sKD+ZiZu3AWiCe9Z9iDj5xWzNvJs7yzD4NtRSRaJo16N19DNgKPAW8DnzL3feY2SNmdtcsm98BvGJmu4FvAw+4e3KONWfVL964gpV1FXzlB/vVqheRSLKFFm6dnZ3e29ub0/f85s63+IO/fpW/uK+TD7xneU7fW0QkG8xsl7t3TvdcQZ4ZO9Wv3LKKloZK/sMTr3Pmwli+yxERySoFPVBaXMQXP3YjBxNn+OPuPfkuR0QkqxT0ods7Gtn6c2v49q5BHnu2P9/liIhkzaxTIBSS3/3AWuLDZ/iPT77B+AQ88C/aMbN8lyUiMicK+jQlxUV85RM3AfClv3+D3oNJ/uRX30esujy/hYmIzIG6bqYoLS7iT++9mc//8vU8d2CYj3z1OZ7drzH2IrJ4KeinYWbcv6mN7zx4OzVLSvjUthf5t/93F3vfPpnv0kRErpjG0c/i/Og4f/5snP/+TD/nRse5paWOX9+wmo/ccC0VZcX5Lk9EBLj8OHoFfYaOnx3h27sG+caOt4gPn6GitJgPvGcZv/S+a3n/2iaqynW4Q0TyR0GfRe5OTzzJ9195m79/7V0SZ0YoLTZuaannjnVN/MyaRm5YWUtxkUbriEjuKOjnydj4BC8OJPnnA0P86MAwe8I+/LrKUjZ1NHL7mhhdbQ10NFVrmKaIzKvLBb36G+agpLiI29c0cvuaRvgIDJ++wPN9wzx3YJjnDgzxxKvvANBQVcZtrfWsbwuC/z3XLlWLX0RyRi36eeLuvJk4y4sDSXYMJHnxYIJDyeBKVjXlJdzaWs/6tga62hq4cWUdZSUaACUiV08t+jwwM1obq2htrOLjtwXXbXn7+Dl2Hkzy4kBw+5N9+wBYUlrEzc0Xg//mlnqN6BGRrFGLPo8Spy+w8+CxIPgPJtj79kkmHEqKjPetqqWrPejq6WxtoFqjekTkMnQwdpE4eX6UXW8eY0c8yYsDCV4ZPMHYhFNcZNywYikb2mN0tQfBv3RJab7LFZEFREG/SJ0dGZsM/h0DCXYfOs7ouFNkcP2KpWxoi9HVHmN9awO1lQp+kUKmoI+IcyPjvPTWMXoGkuyIJ3jp0HFGxiYwg5+6ZildbQ1Bq7+tgfqqsnyXKyI5pKCPqPOj47x86Dg9YYv/x28d4/zoBADXLa+hqz0I/vVtDTRqBk6RSFPQF4iRsQleGTxOTzzBjoEkvQePcW50HIA1y6rpamugqz3GhrYGli1dkudqRSSb5hz0ZrYZ+CpQDHzN3b84w3ofA74N3ObuveGyh4HfBMaBT7v7U5d7LwV99oyOT/Dq4RPsiCfpiSfoPZjkzEgQ/O2NVXS1N9DVFhzgvba2Is/VishczCnozawY2A/cCQwCO4F73X3vlPVqgCeAMmCru/ea2fXAXwHrgRXAD4B17j4+0/sp6OfP2PgEe94+yY6BBD3xJDsHkpwKL4a+OlYZtPjD4F9VX5nnakXkSsz1hKn1QJ+7x8MXexy4G9g7Zb0vAF8CPpu27G7gcXe/AAyYWV/4etuv7EeQbCgpLuKnm+v46eY6ttzRwfiE8/o7J+mJB8H/1J4jfKt3EIBV9RWTob+hLUZzQ4Xm6xFZpDIJ+pXAobTHg0BX+gpmdgvQ7O5PmNlnp2zbM2XblVPfwMy2AFsAWlpaMqtc5qy4yLhhZS03rKzlt97fzsSE88a7p9gxkGBHPMk/vnGEv/5xEPwrapdMnsDV1R6jNVap4BdZJOZ8uqWZFQFfBu6/2tdw98eAxyDouplrTXJ1ioqM61cs5foVS/nXm9qYmHAOHD09GfzP7h/iOy8dBmD50vLJFn9XW4yOpioFv8gClUnQHwaa0x6vCpel1AA3AM+E/9GvAbrN7K4MtpUFrKjIuO6aGq67poZPbWzF3ekfOh0O50yyPZ6g++W3AWisLg+7eYIW/9plmppZZKHI5GBsCcHB2A8QhPRO4JPuvmeG9Z8Bfj88GPte4BtcPBj7Q2CtDsZGg7szMHyGHeEJXD3xJO+ePA8EUzN3hZO0dbXHuG55DUWamllk3szpYKy7j5nZVuApguGV29x9j5k9AvS6e/dltt1jZt8iOHA7Bjx4uZCXxcXMaG+qpr2pmnvXt+DuvJU8GwznDLt7/u61d4HgYiy3tV48c1dz8ovkjk6Yknl1KHl2ssW/YyDJW8mzACxdUsL6cMqGjR0x3nPNUrX4ReZA89FL3jQ3VNLcUMmv3roKCObkTx3c3R5P8IPXjwJBi7+rrYGN7TE2djSybrn6+EWyRS16yau3j5+jJ55ge3+C7fEEg8eCq3DFqsroak8Ff0zX3RWZhea6kUXjUPIs2+OJ4CSu/gRvnwgO7jZWl7Oh/WJXT3ujhnOKpFPXjSwaqa6ej3c2Tx7c3d4fBP/2eILvvxJccL2pppwN7TE2hK3+NgW/yIwU9LJgmRmrY1WsjlVxTziq52DibDhlQ9Dd871wHP+yyeAPWvw6c1fkIgW9LBpmRltjFW2NVZPDOQeGz9ATHthNP4HrmqVLLunqaWlQ8EvhUh+9RIa7Ex8+M9nV0xNPMHx6BIBra5cEoR+2+jVJm0SNDsZKQUpN2RAEfzAnf+JMEPwr6yomR/UEwa9pmWVxU9CLEAT/gaOnJ/v3e+IJjp0dBYJpmdP7+FfW6UIssrgo6EWmMTHh7D96ip5Ui38gwfEw+JsbKiZb+xs7YroClyx4CnqRDExMOPuOnJps7e8YSHLiXBD8q2OVbGiLsaEjOMCr4JeFRkEvchUmJpzX3z0ZjOrpT/DiQIKT5y9eejEV/F1tMVaoq0fyTEEvkgXpl15MTdSWCv6WhsrJ4Zwb2hX8knsKepF5MD7hvBG2+HviCV5M6+pJBX9XW4wNOrgrOaCgF8mB1DV3U2P40/v4mxsqgq6e9uDyi6vqNZxTsktBL5IH6cG/YyAI/uPTDOfcoOCXLFDQiywAqVE96S3+qcHfFV6MRSdwyZVS0IssQFPH8e8YuHgC18q6isnWvoJfMqGgF1kE0oN/x0DykjN3U1M2pObrWVWvuXrkUgp6kUVoYuLilA2prp7klLl6FPySMuegN7PNwFeBYuBr7v7FKc8/ADwIjAOngS3uvtfMWoHXgX3hqj3u/sDl3ktBLzK9iQmnb+hi8PfELwb/inB2zg2anbNgzSnozawY2A/cCQwCO4F73X1v2jpL3f1keP8u4HfcfXMY9N939xsyLVZBL5KZ9EnadkyZnXNF7RK60vr4NR9/9M31UoLrgT53j4cv9jhwNzAZ9KmQD1UBC6s/SCSCzIx1y2tYt7yGT21sxd3pm+zqSfLs/iG+89Jh4OJ8/Ar+wpRJ0K8EDqU9HgS6pq5kZg8CnwHKgJ9Pe6rNzF4CTgJ/5O7PXX25IjITM2Pt8hrWLq/hN8Lg7x86zfawtf/cgYvBn34Frg3tMVbr0ouRlrVLCbr7o8CjZvZJ4I+A+4B3gBZ3T5jZrcB3zey9U/4CwMy2AFsAWlpaslWSSEEzM9Ysq2HNshp+Y8PqS4J/RzzBj/oSfHf3pZde7AqDX9fcjZZM+ug3Ap939w+Hjx8GcPf/NMP6RcAxd6+d5rlngN939xk74dVHL5IbQfCfueTg7vDpCwAsX1p+ycFdBf/CN9c++p3AWjNrAw4D9wCfnPIGa939QPjwF4ED4fImIOnu42bWDqwF4lf3Y4hINgUt/mrWLKvm18MWf3z4zGTov9Cf4G/DFv+ymvJLpmxoa6xS8C8iswa9u4+Z2VbgKYLhldvcfY+ZPQL0uns3sNXMPgiMAscIum0A7gAeMbNRYAJ4wN2T8/GDiMjcmBkdTdV0NFXza12XBn9qVE/3y5cGf2osf7uCf0HTCVMikhF3Z2D4zOS0zD3xBEdPBV09TZMtfgV/vsy160ZEBDOjvama9qZqPtnVgrtzMHE2rY8/wffCFn9jdfklo3o6mhT8+aSgF5GrYma0NVbR1ljFvesvDf4d8QTb4wm+/8o7wMXg72qPsbG9gY6magV/DinoRSQrpgv+Ny9p8SfTgr9sciingn/+KehFZF6YGa2NVbQ2VnFPGPxvJc9Ohv72/gRPpAd/28U+/jXLFPzZpKAXkZwwM1bHqlgdq+ITt10a/DviSbbHEzzxahD8saqyS0b1rFXwz4mCXkTyYrrgP5Q8d8nB3VTwN1aXsbGjkU0dMTatadSFWK6Qgl5EFgQzoyVWSUusko/f1oy7M3jsHNv7E7zQP8zz/RdH9TQ3VLCpo5Hb1zSysT1GU015nqtf2DSOXkQWhdTsnM/3BaHfE09w6vwYANctr2FjR4zbO2J0tceorSjNc7W5pytMiUjkjI1PsOftkzzfP8z2/gQ7DyY5PzpBkcENK2u5vaOR2ztidLbWU1kW/c4LBb2IRN6FsXF2v3Wc5/sTbO8f5qW3jjM24ZQWGze31HN7R4zbOxq5qbmOspKifJebdQp6ESk4Zy6M0fvmMV7oG+aF/gSvvX0Cd6goLea2toYw+GO8d0UtxUWLf0SPgl5ECt6Js6P0DCQmg//A0dMA1CwpYUN7jE0dMW5f07hoh3JqrhsRKXi1laV8+L3X8OH3XgPA0VPngxE9fQleiA/z9N4jQDBBW2oY56Y1jayoq8hn2VmhFr2ICHAoeZYX+of5UV/Q6k9daL2tsYpNa2Js6mhkY0eMusqyPFc6PXXdiIhcgYkJZ9+RUzwfdvP0xBOcHRnHDG5YURu29mPc1trAktLifJcLKOhFROZkdHyClw8d50d9w7zQl+ClQ8cYHXfKiou4dXV90OJf08iNK2spKc7PiB4FvYhIFp25MMaLB5O80Bd09bz+zkkAaspL2NARm+zjz+XkbDoYKyKSRVXlJfzcdcv4ueuWAZA4fYHt8URw1m5fYvLA7rKa8smDupvWxLi2Nj8HdtWiFxHJskPJszzfN8yP+oKzdlMHdtubqtjUEYT+xvZGaiuzN1WDum5ERPIk/cDu833D7BhIcnZkfHKqhk1rGtnU0Uhna/2cDuwq6EVEFoiRsQleHjw+GfypqRrKSor40PXL+dNP3nJVrzvnPnoz2wx8FSgGvubuX5zy/APAg8A4cBrY4u57w+ceBn4zfO7T7v7UVf0UIiIRUFZSxG2tDdzW2sDvfXBdcGB3IMnzfcOUl87PiJ1ZW/RmVgzsB+4EBoGdwL2pIA/XWeruJ8P7dwG/4+6bzex64K+A9cAK4AfAOncfn+n91KIXEblyl2vRZ/LrYz3Q5+5xdx8BHgfuTl8hFfKhKiD12+Nu4HF3v+DuA0Bf+HoiIpIjmXTdrAQOpT0eBLqmrmRmDwKfAcqAn0/btmfKtiun2XYLsAWgpaUlk7pFRCRDWesQcvdH3b0D+APgj65w28fcvdPdO5uamrJVkoiIkFnQHwaa0x6vCpfN5HHgo1e5rYiIZFkmQb8TWGtmbWZWBtwDdKevYGZr0x7+InAgvN8N3GNm5WbWBqwFXpx72SIikqlZ++jdfczMtgJPEQyv3Obue8zsEaDX3buBrWb2QWAUOAbcF267x8y+BewFxoAHLzfiRkREsk8nTImIRMBch1eKiMgituBa9GY2BLw5h5doBIazVE42qa4rs1DrgoVbm+q6Mgu1Lri62la7+7TDFhdc0M+VmfXO9OdLPqmuK7NQ64KFW5vqujILtS7Ifm3quhERiTgFvYhIxEUx6B/LdwEzUF1XZqHWBQu3NtV1ZRZqXZDl2iLXRy8iIpeKYoteRETSKOhFRCIuMkFvZpvNbJ+Z9ZnZQ3mso9nM/snM9prZHjP73XD5583ssJntDm+/kKf6DprZq2ENveGyBjN72swOhP/W57im69L2y24zO2lmv5ePfWZm28zsqJm9lrZs2v1jgf8WfudeMbOruwbc1df1n83sjfC9v2NmdeHyVjM7l7bf/my+6rpMbTN+dmb2cLjP9pnZh3Nc1zfTajpoZrvD5TnbZ5fJiPn7nrn7or8RzMHTD7QTzIf/MnB9nmq5FrglvF9DcHWu64HPA7+/APbVQaBxyrI/AR4K7z8EfCnPn+W7wOp87DPgDuAW4LXZ9g/wC8DfAQZsAHbkuK4PASXh/S+l1dWavl6e9tm0n134f+FloBxoC//fFueqrinP/xfgc7neZ5fJiHn7nkWlRT/rVbByxd3fcfcfh/dPAa8zzcVWFpi7ga+H97/OxWmm8+EDQL+7z+Xs6Kvm7s8CySmLZ9o/dwP/2wM9QJ2ZXZurutz9H9x9LHzYQzANeM7NsM9mkrOrzl2uLjMz4OMElzrNqctkxLx9z6IS9NNdBSvv4WpmrcDNwI5w0dbwT69tue4eSePAP5jZLguu7AWw3N3fCe+/CyzPT2lAMA12+n++hbDPZto/C+l7928IWn0pbWb2kpn9s5m9P081TffZLZR99n7giLsfSFuW8302JSPm7XsWlaBfcMysGvhr4Pc8uKbu/wA6gJuAdwj+bMyHn3H3W4CPAA+a2R3pT3rwt2JextxacL2Du4D/Fy5aKPtsUj73z0zM7A8JpgH/y3DRO0CLu99McHnPb5jZ0hyXteA+uynu5dIGRc732TQZMSnb37OoBP2CupKVmZUSfIB/6e5/A+DuR9x93N0ngD8nTxdJd/fD4b9Hge+EdRxJ/SkY/ns0H7UR/PL5sbsfCWtcEPuMmfdP3r93ZnY/8EvAr4XhQNgtkgjv7yLoB1+Xy7ou89kthH1WAvwK8M3Uslzvs+kygnn8nkUl6Ge9ClauhH1/fwG87u5fTlue3qf2L4HXpm6bg9qqzKwmdZ/gYN5rBPvqvnC1+4C/zXVtoUtaWQthn4Vm2j/dwKfCUREbgBNpf3rPOzPbDPx74C53P5u2vMnMisP77QRXdovnqq7wfWf67BbCVec+CLzh7oOpBbncZzNlBPP5PcvFUeZc3AiOTO8n+E38h3ms42cI/uR6Bdgd3n4B+D/Aq+HybuDaPNTWTjDi4WVgT2o/ATHghwSXgPwB0JCH2qqABFCbtizn+4zgF807BFdLGwR+c6b9QzAK4tHwO/cq0JnjuvoI+m5T37M/C9f9WPj57gZ+DPxyHvbZjJ8d8IfhPtsHfCSXdYXL/xfwwJR1c7bPLpMR8/Y90xQIIiIRF5WuGxERmYGCXkQk4hT0IiIRp6AXEYk4Bb2ISMQp6EVEIk5BLyIScf8fEtEjgzPvkCMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss vs the number of epoch\n",
    "plt.plot(history.history['loss']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and validation sets\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "loss_values = history.history['loss']\n",
    "val_loss_values = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "ax.plot(epochs, loss_values, label='Training loss')\n",
    "ax.plot(epochs, val_loss_values, label='Validation loss')\n",
    "\n",
    "ax.set_title('Training & validation loss')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and validation sets\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "loss_values = history.history['accuracy']\n",
    "val_loss_values = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "ax.plot(epochs, loss_values, label='Training acc')\n",
    "ax.plot(epochs, val_loss_values, label='Validation acc')\n",
    "\n",
    "ax.set_title('Training & validation acc')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.840531587600708"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the training accuracy vs the number of epochs\n",
    "max(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3045024275779724, 0.849833607673645]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the loss and accuracy for the training set \n",
    "results_train = model.evaluate(X_train, y_train)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36704280972480774, 0.840531587600708]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the loss and accuracy for the test set \n",
    "results_val = model.evaluate(X_val, y_val)\n",
    "results_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create simpler model first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "things to add:\n",
    "\n",
    "stopwords\n",
    "lemmetize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tune: \n",
    "\n",
    "layers, num_words, epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw text complaints\n",
    "pos_neg_tweets = pos_neg_df['tweet_text'] \n",
    "\n",
    "# Initialize a tokenizer \n",
    "tokenizer = Tokenizer(num_words=2000) \n",
    "\n",
    "# Fit it to the tweets\n",
    "tokenizer.fit_on_texts(pos_neg_tweets) \n",
    "\n",
    "# Similar to sequences, but returns a numpy array\n",
    "one_hot_results= tokenizer.texts_to_matrix(pos_neg_tweets, mode='binary') \n",
    "\n",
    "# Useful if we wish to decode (more explanation below)\n",
    "word_index = tokenizer.word_index \n",
    "\n",
    "# Tokens are the number of unique words across the corpus\n",
    "print('Found %s unique tokens.' % len(word_index)) \n",
    "\n",
    "# Our coded data\n",
    "print('Dimensions of our coded results:', np.shape(one_hot_results)) \n",
    "one_hot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Two layers with relu activation\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "\n",
    "# One layer with softmax activation \n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=500,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGEX code for 3+ characters:    r\"(?u)\\w{3,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(pos_neg_tweets,pos_neg_sentiment, test_size=0.15, random_state=42, stratify=pos_neg_sentiment)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Custom text prep transformer\n",
    "# ---------------------------\n",
    "\n",
    "class TextPrep(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, remove_stopwords=False):\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Flatten if array is 2D\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = X.ravel()\n",
    "        # Convert to list of strings\n",
    "        X = [str(x) for x in X]\n",
    "\n",
    "        if self.remove_stopwords:\n",
    "            X = [\n",
    "                \" \".join([w for w in text.split() if w.lower() not in self.stop_words])\n",
    "                for text in X\n",
    "            ]\n",
    "        return X    \n",
    "    \n",
    "# ---------------------------\n",
    "# Step 2: Wrap tokenizer for sklearn\n",
    "# ---------------------------\n",
    "class KerasTokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_words=5000, mode=\"binary\"):\n",
    "        self.num_words = num_words\n",
    "        self.mode = mode\n",
    "        self.tokenizer = Tokenizer(num_words=self.num_words)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.tokenizer.fit_on_texts(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.tokenizer.texts_to_matrix(X, mode=self.mode)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Build a Keras model\n",
    "# ---------------------------\n",
    "def build_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation='relu', input_shape=(input_dim,)))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Pipeline\n",
    "# ---------------------------\n",
    "pipeline = Pipeline([\n",
    "    (\"prep\", TextPrep()),\n",
    "    (\"tok\", KerasTokenizer(num_words=2000, mode=\"binary\")),\n",
    "    (\"clf\", KerasClassifier(build_fn=lambda: build_model(2000), \n",
    "                            epochs=200, \n",
    "                            batch_size=256,\n",
    "                            clf__validation_data=(X_val, y_val)\n",
    "                            ))\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Custom text prep transformer\n",
    "# ---------------------------\n",
    "class TextPrep(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, remove_stopwords=False):\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = X.ravel()\n",
    "        X = [str(x) for x in X]\n",
    "        if self.remove_stopwords:\n",
    "            X = [\n",
    "                \" \".join([w for w in text.split() if w.lower() not in self.stop_words])\n",
    "                for text in X\n",
    "            ]\n",
    "        return X\n",
    "\n",
    "# ---------------------------\n",
    "# Step 2: Wrap tokenizer\n",
    "# ---------------------------\n",
    "class KerasTokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_words=2000, mode=\"binary\"):\n",
    "        self.num_words = num_words\n",
    "        self.mode = mode\n",
    "        self.tokenizer = Tokenizer(num_words=self.num_words)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.tokenizer.fit_on_texts(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.tokenizer.texts_to_matrix(X, mode=self.mode)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Build model factory\n",
    "# ---------------------------\n",
    "def build_model(input_dim, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation=\"relu\", input_shape=(input_dim,)))\n",
    "    model.add(Dense(25, activation=\"relu\"))\n",
    "    model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Setup pipeline\n",
    "# ---------------------------\n",
    "n_classes = len(np.unique(y_train))  # adjust to your labels\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"prep\", TextPrep()),\n",
    "    (\"tok\", KerasTokenizer()),\n",
    "    (\"clf\", KerasClassifier(\n",
    "        build_fn=lambda: build_model(\n",
    "            input_dim=pipeline.named_steps[\"tok\"].num_words, \n",
    "            n_classes=n_classes\n",
    "        ),\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        verbose=1,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)]\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # ---------------------------\n",
    "# # Step 5: Fit\n",
    "# # ---------------------------\n",
    "# pipeline.fit(\n",
    "#     X_train, y_train,\n",
    "#     prep__remove_stopwords=True,  # toggle stopword removal\n",
    "#     tok__num_words=5000           # dynamically set number of words\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'history_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-252550c7205d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Access history directly (no `.history`)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpipe_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"clf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Plot accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'history_'"
     ]
    }
   ],
   "source": [
    "# Access history directly (no `.history`)\n",
    "pipe_history = pipeline.named_steps[\"clf\"].history_\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(pipe_history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "if \"val_accuracy\" in pipe_history:\n",
    "    plt.plot(pipe_history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Epoch vs Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    # Plot accuracy\\n    plt.figure(figsize=(8,5))\\n    plt.plot(pipe_history[\"accuracy\"], label=\"Train Accuracy\")\\n    if \"val_accuracy\" in pipe_history:\\n        plt.plot(pipe_history[\"val_accuracy\"], label=\"Validation Accuracy\")\\n    plt.title(\"Epoch vs Accuracy\")\\n    plt.xlabel(\"Epoch\")\\n    plt.ylabel(\"Accuracy\")\\n    plt.legend()\\n    plt.show()\\n    \\n    # Access the fitted Keras model\\n    model = pipeline.named_steps[\"clf\"].model\\n\\n    # Transform X_test through the pipeline up to the tokenizer\\n    X_test_transformed = pipeline.named_steps[\"tok\"].transform(\\n        pipeline.named_steps[\"prep\"].transform(X_test)\\n    )\\n\\n    # Evaluate\\n    loss, acc = model.evaluate(X_test_transformed, y_test, verbose=1)\\n    print(\"Test Loss:\", loss)\\n    print(\"Test Accuracy:\", acc)\\n    '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_pipe(X,y,num_words=2000, remove_stopwords=False, num_epochs=50):\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 1: Custom text prep transformer\n",
    "    # ---------------------------\n",
    "    class TextPrep(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self):\n",
    "            self.remove_stopwords = remove_stopwords\n",
    "            self.stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X = X.ravel()\n",
    "            X = [str(x) for x in X]\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                X = [\n",
    "                    \" \".join([w for w in text.split() if w.lower() not in self.stop_words])\n",
    "                    for text in X\n",
    "                ]\n",
    "            return X\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 2: Wrap tokenizer\n",
    "    # ---------------------------\n",
    "    class KerasTokenizer(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, mode=\"binary\"):\n",
    "            self.num_words = num_words\n",
    "            self.mode = mode\n",
    "            self.tokenizer = Tokenizer(num_words=self.num_words)\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            self.tokenizer.fit_on_texts(X)\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            return self.tokenizer.texts_to_matrix(X, mode=self.mode)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 3: Build model factory\n",
    "    # ---------------------------\n",
    "    def build_model(input_dim, n_classes):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(50, activation=\"relu\", input_shape=(input_dim,)))\n",
    "        model.add(Dense(25, activation=\"relu\"))\n",
    "        model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "        model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 4: Setup pipeline\n",
    "    # ---------------------------\n",
    "    n_classes = len(np.unique(y_train))  # adjust to your labels\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"prep\", TextPrep()),\n",
    "        (\"tok\", KerasTokenizer()),\n",
    "        (\"clf\", KerasClassifier(\n",
    "            build_fn=lambda: build_model(\n",
    "                input_dim=pipeline.named_steps[\"tok\"].num_words, \n",
    "                n_classes=n_classes\n",
    "            ),\n",
    "            epochs=num_epochs,\n",
    "            batch_size=256,\n",
    "            verbose=1,\n",
    "            validation_split=0.2\n",
    "            , callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)]\n",
    "        ))\n",
    "    ])\n",
    "    # ---------------------------\n",
    "    # Step 5: Fit\n",
    "    # ---------------------------\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    # Access history directly (no `.history`)\n",
    "    pipe_history = pipeline.named_steps[\"clf\"].history_\n",
    "\n",
    "    test_acc = pipeline.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Test Accuracy:\", acc)\n",
    "\n",
    "    # Detailed classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "\"\"\"    # Plot accuracy\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(pipe_history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "    if \"val_accuracy\" in pipe_history:\n",
    "        plt.plot(pipe_history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "    plt.title(\"Epoch vs Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Access the fitted Keras model\n",
    "    model = pipeline.named_steps[\"clf\"].model\n",
    "\n",
    "    # Transform X_test through the pipeline up to the tokenizer\n",
    "    X_test_transformed = pipeline.named_steps[\"tok\"].transform(\n",
    "        pipeline.named_steps[\"prep\"].transform(X_test)\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    loss, acc = model.evaluate(X_test_transformed, y_test, verbose=1)\n",
    "    print(\"Test Loss:\", loss)\n",
    "    print(\"Test Accuracy:\", acc)\n",
    "    \"\"\"\n",
    "    \n",
    "#     return pipeline;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 35.8 GiB for an array with shape (4808000, 1000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-08a4d2dbb8e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-333436761a9d>\u001b[0m in \u001b[0;36mrun_pipe\u001b[1;34m(X, y, num_words, remove_stopwords, num_epochs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m# Step 5: Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# ---------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;31m# Access history directly (no `.history`)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mpipe_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"clf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \"\"\"\n\u001b[0;32m    377\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pipeline\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    337\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    871\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-333436761a9d>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# ---------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\src\\preprocessing\\text.py\u001b[0m in \u001b[0;36mtexts_to_matrix\u001b[1;34m(self, texts, mode)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m    463\u001b[0m         \u001b[0msequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequences_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msequences_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\src\\preprocessing\\text.py\u001b[0m in \u001b[0;36msequences_to_matrix\u001b[1;34m(self, sequences, mode)\u001b[0m\n\u001b[0;32m    495\u001b[0m             )\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 35.8 GiB for an array with shape (4808000, 1000) and data type float64"
     ]
    }
   ],
   "source": [
    "run_pipe(X_train_full,y_train_full, num_words=1000, num_epochs=50, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_pipe(X_train,y_train, num_words=500, num_epochs=50, remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
